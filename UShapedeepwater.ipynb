{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UShapedeepwater.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#! git clone https://github.com/LintaoPeng/U-shape_Transformer_for_Underwater_Image_Enhancement"
      ],
      "metadata": {
        "id": "Dlshqz5b5HU2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "id": "Te2YyNi6hzkO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files"
      ],
      "metadata": {
        "id": "jVJwW21hUw90"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from utility.ptcolor import rgb2lab\n",
        "#from utility.Qnt import quantAB,quantL\n",
        "import torch\n",
        "from torch.nn import functional\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class lab_Loss(nn.Module):\n",
        "    def __init__(self, alpha=1,weight=1,levels=7,vmin=-80,vmax=80):\n",
        "        super(lab_Loss, self).__init__()\n",
        "        self.alpha=alpha\n",
        "        self.weight=weight\n",
        "        self.levels=levels\n",
        "        self.vmin=vmin\n",
        "        self.vmax=vmax\n",
        "\n",
        "    def Hist_2_Dist_L(self,img, tab,alpha):\n",
        "        img_dist=((img.unsqueeze(1)-tab)**2)\n",
        "        p=functional.softmax(-alpha*img_dist,dim=1)\n",
        "        return p\n",
        "\n",
        "    def Hist_2_Dist_AB(self,img,tab,alpha):\n",
        "        img_dist=((img.unsqueeze(1)-tab)**2).sum(2)\n",
        "        p = torch.nn.functional.softmax(-alpha*img_dist, dim=1)\n",
        "        return p\n",
        "\n",
        "    def loss_ab(self,img,gt,alpha,tab,levels):\n",
        "        p= self.Hist_2_Dist_AB(img, tab,alpha).cuda()\n",
        "        q= self.Hist_2_Dist_AB(gt,tab,alpha).cuda()\n",
        "        p = torch.clamp(p, 0.001, 0.999)\n",
        "        loss = -(q*torch.log(p)).sum([1,2,3]).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,img,gt):\n",
        "\t    tab=quantAB(self.levels,self.vmin,self.vmax).cuda()\n",
        "\t    lab_img=torch.clamp(rgb2lab(img),self.vmin,self.vmax)\n",
        "\t    lab_gt=torch.clamp(rgb2lab(gt),self.vmin,self.vmax)\n",
        "\n",
        "\t    loss_l=torch.abs(lab_img[:,0,:,:]-lab_gt[:,0,:,:]).mean()\n",
        "\t    loss_AB=self.loss_ab(lab_img[:,1:,:,:],lab_gt[:,1:,:,:],self.alpha,tab,self.levels)\n",
        "\t    loss=loss_l+self.weight*loss_AB\n",
        "\t    #return (loss,loss_l,loss_AB)\n",
        "\t    return loss"
      ],
      "metadata": {
        "id": "xvzC9V4jD8Xo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#from utilities import ptcolor as ptcolor\n",
        "import torch.nn as nn\n",
        "\n",
        "class lch_Loss(nn.Module):\n",
        "    def __init__(self, weightC=1,weightH=1,levels=4,eps=0.01,weight=None):\n",
        "        super(lch_Loss, self).__init__()\n",
        "        self.weightC=weightC\n",
        "        self.weightH=weightH\n",
        "        self.levels=levels\n",
        "        self.eps=eps\n",
        "        self.weight=weight\n",
        "\n",
        "\n",
        "    def hue_to_distribution(self,h, levels, eps=0.0):\n",
        "        h = h * (levels / 360.0)\n",
        "        a = torch.arange(levels).float().to(h.device)\n",
        "        a = a.view(1, levels, 1, 1)\n",
        "        h=h.unsqueeze(1)\n",
        "        p = torch.relu(1 - torch.abs(h - a))\n",
        "        p = p + (a == 0.0).float() * p[:, -1:, :, :]\n",
        "        p = (p + torch.ones_like(p) * eps) / (1.0 + levels * eps)\n",
        "        return p\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,img,gt):\n",
        "        img_lch= ptcolor.rgb2lch(img)\n",
        "        gt_lch= ptcolor.rgb2lch(gt)\n",
        "        loss_L=torch.mean(torch.abs(img_lch[:,0,:,:]-gt_lch[:,0,:,:]))\n",
        "        loss_C=torch.mean(torch.abs(img_lch[:,1,:,:]-gt_lch[:,1,:,:]))\n",
        "        img_H_Dist=torch.clamp(self.hue_to_distribution(img_lch[:,2,:,:],self.levels,self.eps),0.001, 0.999)\n",
        "        gt_H_Dist =torch.clamp(self.hue_to_distribution(gt_lch[:, 2, :, :], self.levels),0.001, 0.999)\n",
        "        if self.weight is None:\n",
        "            loss_H = torch.mean(-torch.mul(gt_H_Dist, torch.log(img_H_Dist)))\n",
        "        else:\n",
        "            loss_H = -(gt_lch[:,1,:,:]*(gt_H_Dist*torch.log(img_H_Dist)).sum(1,keepdim=True)).mean()\n",
        "        loss=loss_L+self.weightC*loss_C+self.weightH*loss_H\n",
        "        #return(loss,loss_L,loss_C,loss_H)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "K8jNbwICE0-a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import copy\n",
        "import logging\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import Dropout, Softmax, Conv2d, LayerNorm\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "\n",
        "#KV_size = 480\n",
        "#transformer.num_heads  = 4\n",
        "#transformer.num_layers = 4\n",
        "#expand_ratio           = 4\n",
        "\n",
        "\n",
        "\n",
        "#线性编码\n",
        "class Channel_Embeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from patch, position embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, patchsize, img_size, in_channels):\n",
        "        super().__init__()\n",
        "        img_size = _pair(img_size)\n",
        "        patch_size = _pair(patchsize)\n",
        "        n_patches = (img_size[0] // patch_size[0]) * (img_size[1] // patch_size[1])\n",
        "\n",
        "        self.patch_embeddings = Conv2d(in_channels=in_channels,\n",
        "                                       out_channels=in_channels,\n",
        "                                       kernel_size=patch_size,\n",
        "                                       stride=patch_size)\n",
        "        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches, in_channels))\n",
        "        self.dropout = Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x is None:\n",
        "            return None\n",
        "        x = self.patch_embeddings(x)  # (B, hidden，n_patches^(1/2), n_patches^(1/2))\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(-1, -2)  # (B, n_patches, hidden)\n",
        "        embeddings = x + self.position_embeddings\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "#特征重组\n",
        "class Reconstruct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n",
        "        super(Reconstruct, self).__init__()\n",
        "        if kernel_size == 3:\n",
        "            padding = 1\n",
        "        else:\n",
        "            padding = 0\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,kernel_size=kernel_size, padding=padding)\n",
        "        self.norm = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x is None:\n",
        "            return None\n",
        "\n",
        "        # reshape from (B, n_patch, hidden) to (B, h, w, hidden)\n",
        "        B, n_patch, hidden = x.size()  \n",
        "        h, w = int(np.sqrt(n_patch)), int(np.sqrt(n_patch))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = x.contiguous().view(B, hidden, h, w)\n",
        "        x = nn.Upsample(scale_factor=self.scale_factor)(x)\n",
        "\n",
        "        out = self.conv(x)\n",
        "        out = self.norm(out)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class Attention_org(nn.Module):\n",
        "    def __init__(self, vis,channel_num, KV_size=480, num_heads=4):\n",
        "        super(Attention_org, self).__init__()\n",
        "        self.vis = vis\n",
        "        self.KV_size = KV_size\n",
        "        self.channel_num = channel_num\n",
        "        self.num_attention_heads = num_heads\n",
        "\n",
        "        self.query1 = nn.ModuleList()\n",
        "        self.query2 = nn.ModuleList()\n",
        "        self.query3 = nn.ModuleList()\n",
        "        self.query4 = nn.ModuleList()\n",
        "        self.key = nn.ModuleList()\n",
        "        self.value = nn.ModuleList()\n",
        "\n",
        "        for _ in range(num_heads):\n",
        "            query1 = nn.Linear(channel_num[0], channel_num[0], bias=False)\n",
        "            query2 = nn.Linear(channel_num[1], channel_num[1], bias=False)\n",
        "            query3 = nn.Linear(channel_num[2], channel_num[2], bias=False)\n",
        "            query4 = nn.Linear(channel_num[3], channel_num[3], bias=False)\n",
        "            key = nn.Linear( self.KV_size,  self.KV_size, bias=False)\n",
        "            value = nn.Linear(self.KV_size,  self.KV_size, bias=False)\n",
        "            #把所有的值都重新复制一遍，deepcopy为深复制，完全脱离原来的值，即将被复制对象完全再复制一遍作为独立的新个体单独存在\n",
        "            self.query1.append(copy.deepcopy(query1))\n",
        "            self.query2.append(copy.deepcopy(query2))\n",
        "            self.query3.append(copy.deepcopy(query3))\n",
        "            self.query4.append(copy.deepcopy(query4))\n",
        "            self.key.append(copy.deepcopy(key))\n",
        "            self.value.append(copy.deepcopy(value))\n",
        "        self.psi = nn.InstanceNorm2d(self.num_attention_heads)\n",
        "        self.softmax = Softmax(dim=3)\n",
        "        self.out1 = nn.Linear(channel_num[0], channel_num[0], bias=False)\n",
        "        self.out2 = nn.Linear(channel_num[1], channel_num[1], bias=False)\n",
        "        self.out3 = nn.Linear(channel_num[2], channel_num[2], bias=False)\n",
        "        self.out4 = nn.Linear(channel_num[3], channel_num[3], bias=False)\n",
        "        self.attn_dropout = Dropout(0.1)\n",
        "        self.proj_dropout = Dropout(0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, emb1,emb2,emb3,emb4, emb_all):\n",
        "        multi_head_Q1_list = []\n",
        "        multi_head_Q2_list = []\n",
        "        multi_head_Q3_list = []\n",
        "        multi_head_Q4_list = []\n",
        "        multi_head_K_list = []\n",
        "        multi_head_V_list = []\n",
        "        if emb1 is not None:\n",
        "            for query1 in self.query1:\n",
        "                Q1 = query1(emb1)\n",
        "                multi_head_Q1_list.append(Q1)\n",
        "        if emb2 is not None:\n",
        "            for query2 in self.query2:\n",
        "                Q2 = query2(emb2)\n",
        "                multi_head_Q2_list.append(Q2)\n",
        "        if emb3 is not None:\n",
        "            for query3 in self.query3:\n",
        "                Q3 = query3(emb3)\n",
        "                multi_head_Q3_list.append(Q3)\n",
        "        if emb4 is not None:\n",
        "            for query4 in self.query4:\n",
        "                Q4 = query4(emb4)\n",
        "                multi_head_Q4_list.append(Q4)\n",
        "        for key in self.key:\n",
        "            K = key(emb_all)\n",
        "            multi_head_K_list.append(K)\n",
        "        for value in self.value:\n",
        "            V = value(emb_all)\n",
        "            multi_head_V_list.append(V)\n",
        "        # print(len(multi_head_Q4_list))\n",
        "\n",
        "        multi_head_Q1 = torch.stack(multi_head_Q1_list, dim=1) if emb1 is not None else None\n",
        "        multi_head_Q2 = torch.stack(multi_head_Q2_list, dim=1) if emb2 is not None else None\n",
        "        multi_head_Q3 = torch.stack(multi_head_Q3_list, dim=1) if emb3 is not None else None\n",
        "        multi_head_Q4 = torch.stack(multi_head_Q4_list, dim=1) if emb4 is not None else None\n",
        "        multi_head_K = torch.stack(multi_head_K_list, dim=1)\n",
        "        multi_head_V = torch.stack(multi_head_V_list, dim=1)\n",
        "\n",
        "        multi_head_Q1 = multi_head_Q1.transpose(-1, -2) if emb1 is not None else None\n",
        "        multi_head_Q2 = multi_head_Q2.transpose(-1, -2) if emb2 is not None else None\n",
        "        multi_head_Q3 = multi_head_Q3.transpose(-1, -2) if emb3 is not None else None\n",
        "        multi_head_Q4 = multi_head_Q4.transpose(-1, -2) if emb4 is not None else None\n",
        "\n",
        "        attention_scores1 = torch.matmul(multi_head_Q1, multi_head_K) if emb1 is not None else None\n",
        "        attention_scores2 = torch.matmul(multi_head_Q2, multi_head_K) if emb2 is not None else None\n",
        "        attention_scores3 = torch.matmul(multi_head_Q3, multi_head_K) if emb3 is not None else None\n",
        "        attention_scores4 = torch.matmul(multi_head_Q4, multi_head_K) if emb4 is not None else None\n",
        "\n",
        "        attention_scores1 = attention_scores1 / math.sqrt(self.KV_size) if emb1 is not None else None\n",
        "        attention_scores2 = attention_scores2 / math.sqrt(self.KV_size) if emb2 is not None else None\n",
        "        attention_scores3 = attention_scores3 / math.sqrt(self.KV_size) if emb3 is not None else None\n",
        "        attention_scores4 = attention_scores4 / math.sqrt(self.KV_size) if emb4 is not None else None\n",
        "\n",
        "        attention_probs1 = self.softmax(self.psi(attention_scores1)) if emb1 is not None else None\n",
        "        attention_probs2 = self.softmax(self.psi(attention_scores2)) if emb2 is not None else None\n",
        "        attention_probs3 = self.softmax(self.psi(attention_scores3)) if emb3 is not None else None\n",
        "        attention_probs4 = self.softmax(self.psi(attention_scores4)) if emb4 is not None else None\n",
        "        # print(attention_probs4.size())\n",
        "\n",
        "        if self.vis:\n",
        "            weights =  []\n",
        "            weights.append(attention_probs1.mean(1))\n",
        "            weights.append(attention_probs2.mean(1))\n",
        "            weights.append(attention_probs3.mean(1))\n",
        "            weights.append(attention_probs4.mean(1))\n",
        "        else: weights=None\n",
        "\n",
        "        attention_probs1 = self.attn_dropout(attention_probs1) if emb1 is not None else None\n",
        "        attention_probs2 = self.attn_dropout(attention_probs2) if emb2 is not None else None\n",
        "        attention_probs3 = self.attn_dropout(attention_probs3) if emb3 is not None else None\n",
        "        attention_probs4 = self.attn_dropout(attention_probs4) if emb4 is not None else None\n",
        "\n",
        "        multi_head_V = multi_head_V.transpose(-1, -2)\n",
        "        context_layer1 = torch.matmul(attention_probs1, multi_head_V) if emb1 is not None else None\n",
        "        context_layer2 = torch.matmul(attention_probs2, multi_head_V) if emb2 is not None else None\n",
        "        context_layer3 = torch.matmul(attention_probs3, multi_head_V) if emb3 is not None else None\n",
        "        context_layer4 = torch.matmul(attention_probs4, multi_head_V) if emb4 is not None else None\n",
        "\n",
        "        context_layer1 = context_layer1.permute(0, 3, 2, 1).contiguous() if emb1 is not None else None\n",
        "        context_layer2 = context_layer2.permute(0, 3, 2, 1).contiguous() if emb2 is not None else None\n",
        "        context_layer3 = context_layer3.permute(0, 3, 2, 1).contiguous() if emb3 is not None else None\n",
        "        context_layer4 = context_layer4.permute(0, 3, 2, 1).contiguous() if emb4 is not None else None\n",
        "        context_layer1 = context_layer1.mean(dim=3) if emb1 is not None else None\n",
        "        context_layer2 = context_layer2.mean(dim=3) if emb2 is not None else None\n",
        "        context_layer3 = context_layer3.mean(dim=3) if emb3 is not None else None\n",
        "        context_layer4 = context_layer4.mean(dim=3) if emb4 is not None else None\n",
        "\n",
        "        O1 = self.out1(context_layer1) if emb1 is not None else None\n",
        "        O2 = self.out2(context_layer2) if emb2 is not None else None\n",
        "        O3 = self.out3(context_layer3) if emb3 is not None else None\n",
        "        O4 = self.out4(context_layer4) if emb4 is not None else None\n",
        "        O1 = self.proj_dropout(O1) if emb1 is not None else None\n",
        "        O2 = self.proj_dropout(O2) if emb2 is not None else None\n",
        "        O3 = self.proj_dropout(O3) if emb3 is not None else None\n",
        "        O4 = self.proj_dropout(O4) if emb4 is not None else None\n",
        "        return O1,O2,O3,O4, weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_channel, mlp_channel):\n",
        "        super(Mlp, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_channel, mlp_channel)\n",
        "        self.fc2 = nn.Linear(mlp_channel, in_channel)\n",
        "        self.act_fn = nn.GELU()\n",
        "        self.dropout = Dropout(0.0)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
        "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block_ViT(nn.Module):\n",
        "    def __init__(self, vis, channel_num, expand_ratio=4,KV_size=480):\n",
        "        super(Block_ViT, self).__init__()\n",
        "        expand_ratio = 4\n",
        "        self.attn_norm1 = LayerNorm(channel_num[0],eps=1e-6)\n",
        "        self.attn_norm2 = LayerNorm(channel_num[1],eps=1e-6)\n",
        "        self.attn_norm3 = LayerNorm(channel_num[2],eps=1e-6)\n",
        "        self.attn_norm4 = LayerNorm(channel_num[3],eps=1e-6)\n",
        "        self.attn_norm =  LayerNorm(KV_size,eps=1e-6)\n",
        "        self.channel_attn = Attention_org(vis, channel_num)\n",
        "\n",
        "        self.ffn_norm1 = LayerNorm(channel_num[0],eps=1e-6)\n",
        "        self.ffn_norm2 = LayerNorm(channel_num[1],eps=1e-6)\n",
        "        self.ffn_norm3 = LayerNorm(channel_num[2],eps=1e-6)\n",
        "        self.ffn_norm4 = LayerNorm(channel_num[3],eps=1e-6)\n",
        "        self.ffn1 = Mlp(channel_num[0],channel_num[0]*expand_ratio)\n",
        "        self.ffn2 = Mlp(channel_num[1],channel_num[1]*expand_ratio)\n",
        "        self.ffn3 = Mlp(channel_num[2],channel_num[2]*expand_ratio)\n",
        "        self.ffn4 = Mlp(channel_num[3],channel_num[3]*expand_ratio)\n",
        "\n",
        "\n",
        "    def forward(self, emb1,emb2,emb3,emb4):\n",
        "        embcat = []\n",
        "        org1 = emb1\n",
        "        org2 = emb2\n",
        "        org3 = emb3\n",
        "        org4 = emb4\n",
        "        for i in range(4):\n",
        "            var_name = \"emb\"+str(i+1)  #emb1,emb2,emb3,emb4\n",
        "            tmp_var = locals()[var_name]\n",
        "            if tmp_var is not None:\n",
        "                embcat.append(tmp_var)\n",
        "\n",
        "        emb_all = torch.cat(embcat,dim=2)\n",
        "        cx1 = self.attn_norm1(emb1) if emb1 is not None else None\n",
        "        cx2 = self.attn_norm2(emb2) if emb2 is not None else None\n",
        "        cx3 = self.attn_norm3(emb3) if emb3 is not None else None\n",
        "        cx4 = self.attn_norm4(emb4) if emb4 is not None else None\n",
        "        emb_all = self.attn_norm(emb_all)\n",
        "        cx1,cx2,cx3,cx4, weights = self.channel_attn(cx1,cx2,cx3,cx4,emb_all)\n",
        "        #残差\n",
        "        cx1 = org1 + cx1 if emb1 is not None else None\n",
        "        cx2 = org2 + cx2 if emb2 is not None else None\n",
        "        cx3 = org3 + cx3 if emb3 is not None else None\n",
        "        cx4 = org4 + cx4 if emb4 is not None else None\n",
        "\n",
        "        org1 = cx1\n",
        "        org2 = cx2\n",
        "        org3 = cx3\n",
        "        org4 = cx4\n",
        "        x1 = self.ffn_norm1(cx1) if emb1 is not None else None\n",
        "        x2 = self.ffn_norm2(cx2) if emb2 is not None else None\n",
        "        x3 = self.ffn_norm3(cx3) if emb3 is not None else None\n",
        "        x4 = self.ffn_norm4(cx4) if emb4 is not None else None\n",
        "        x1 = self.ffn1(x1) if emb1 is not None else None\n",
        "        x2 = self.ffn2(x2) if emb2 is not None else None\n",
        "        x3 = self.ffn3(x3) if emb3 is not None else None\n",
        "        x4 = self.ffn4(x4) if emb4 is not None else None\n",
        "        #残差\n",
        "        x1 = x1 + org1 if emb1 is not None else None\n",
        "        x2 = x2 + org2 if emb2 is not None else None\n",
        "        x3 = x3 + org3 if emb3 is not None else None\n",
        "        x4 = x4 + org4 if emb4 is not None else None\n",
        "\n",
        "        return x1, x2, x3, x4, weights\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vis, channel_num, num_layers=4):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.vis = vis\n",
        "        self.layer = nn.ModuleList()\n",
        "        self.encoder_norm1 = LayerNorm(channel_num[0],eps=1e-6)\n",
        "        self.encoder_norm2 = LayerNorm(channel_num[1],eps=1e-6)\n",
        "        self.encoder_norm3 = LayerNorm(channel_num[2],eps=1e-6)\n",
        "        self.encoder_norm4 = LayerNorm(channel_num[3],eps=1e-6)\n",
        "        for _ in range(num_layers):\n",
        "            layer = Block_ViT(vis, channel_num)\n",
        "            self.layer.append(copy.deepcopy(layer))\n",
        "\n",
        "    def forward(self, emb1,emb2,emb3,emb4):\n",
        "        attn_weights = []\n",
        "        for layer_block in self.layer:\n",
        "            emb1,emb2,emb3,emb4, weights = layer_block(emb1,emb2,emb3,emb4)\n",
        "            if self.vis:\n",
        "                attn_weights.append(weights)\n",
        "        emb1 = self.encoder_norm1(emb1) if emb1 is not None else None\n",
        "        emb2 = self.encoder_norm2(emb2) if emb2 is not None else None\n",
        "        emb3 = self.encoder_norm3(emb3) if emb3 is not None else None\n",
        "        emb4 = self.encoder_norm4(emb4) if emb4 is not None else None\n",
        "        return emb1,emb2,emb3,emb4, attn_weights\n",
        "\n",
        "\n",
        "class ChannelTransformer(nn.Module):\n",
        "    def __init__(self,  vis=False, img_size=256, channel_num=[64, 128, 256, 512], patchSize=[32, 16, 8, 4]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patchSize_1 = patchSize[0]\n",
        "        self.patchSize_2 = patchSize[1]\n",
        "        self.patchSize_3 = patchSize[2]\n",
        "        self.patchSize_4 = patchSize[3]\n",
        "        self.embeddings_1 = Channel_Embeddings(self.patchSize_1, img_size=img_size,    in_channels=channel_num[0])\n",
        "        self.embeddings_2 = Channel_Embeddings(self.patchSize_2, img_size=img_size//2, in_channels=channel_num[1])\n",
        "        self.embeddings_3 = Channel_Embeddings(self.patchSize_3, img_size=img_size//4, in_channels=channel_num[2])\n",
        "        self.embeddings_4 = Channel_Embeddings(self.patchSize_4, img_size=img_size//8, in_channels=channel_num[3])\n",
        "        self.encoder = Encoder( vis, channel_num)\n",
        "\n",
        "        self.reconstruct_1 = Reconstruct(channel_num[0], channel_num[0], kernel_size=1,scale_factor=(self.patchSize_1,self.patchSize_1))\n",
        "        self.reconstruct_2 = Reconstruct(channel_num[1], channel_num[1], kernel_size=1,scale_factor=(self.patchSize_2,self.patchSize_2))\n",
        "        self.reconstruct_3 = Reconstruct(channel_num[2], channel_num[2], kernel_size=1,scale_factor=(self.patchSize_3,self.patchSize_3))\n",
        "        self.reconstruct_4 = Reconstruct(channel_num[3], channel_num[3], kernel_size=1,scale_factor=(self.patchSize_4,self.patchSize_4))\n",
        "\n",
        "    def forward(self,en1,en2,en3,en4):\n",
        "\n",
        "        emb1 = self.embeddings_1(en1)\n",
        "        emb2 = self.embeddings_2(en2)\n",
        "        emb3 = self.embeddings_3(en3)\n",
        "        emb4 = self.embeddings_4(en4)\n",
        "\n",
        "        encoded1, encoded2, encoded3, encoded4, attn_weights = self.encoder(emb1,emb2,emb3,emb4)  # (B, n_patch, hidden)\n",
        "        x1 = self.reconstruct_1(encoded1) if en1 is not None else None\n",
        "        x2 = self.reconstruct_2(encoded2) if en2 is not None else None\n",
        "        x3 = self.reconstruct_3(encoded3) if en3 is not None else None\n",
        "        x4 = self.reconstruct_4(encoded4) if en4 is not None else None\n",
        "\n",
        "        x1 = x1 + en1  if en1 is not None else None\n",
        "        x2 = x2 + en2  if en2 is not None else None\n",
        "        x3 = x3 + en3  if en3 is not None else None\n",
        "        x4 = x4 + en4  if en4 is not None else None\n",
        "\n",
        "        return x1, x2, x3, x4, attn_weights"
      ],
      "metadata": {
        "id": "fXJismTtE2OR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class IntermediateSequential(nn.Sequential):\n",
        "    def __init__(self, *args, return_intermediate=False):\n",
        "        super().__init__(*args)\n",
        "        self.return_intermediate = return_intermediate\n",
        "\n",
        "    def forward(self, input): \n",
        "        if not self.return_intermediate:\n",
        "            return super().forward(input)\n",
        "\n",
        "        intermediate_outputs = {}\n",
        "        output = input\n",
        "        for name, module in self.named_children():\n",
        "            output = intermediate_outputs[name] = module(output)\n",
        "\n",
        "        return output, intermediate_outputs"
      ],
      "metadata": {
        "id": "4HzNrvp-GZQJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "#实现了位置编码\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_length=512):\n",
        "        super(FixedPositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_length, embedding_dim)\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, embedding_dim, 2).float()\n",
        "            * (-torch.log(torch.tensor(10000.0)) / embedding_dim)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class LearnedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_position_embeddings, embedding_dim, seq_length):\n",
        "        super(LearnedPositionalEncoding, self).__init__()\n",
        "\n",
        "        self.position_embeddings = nn.Parameter(torch.zeros(1, 256, 512)) #8x\n",
        "\n",
        "    def forward(self, x, position_ids=None):\n",
        "\n",
        "        position_embeddings = self.position_embeddings\n",
        "        return x + position_embeddings"
      ],
      "metadata": {
        "id": "Go1kxgzBGgOs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#from net.IntmdSequential import IntermediateSequential\n",
        "\n",
        "\n",
        "#实现了自注意力机制，相当于unet的bottleneck层\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, dim, heads=8, qkv_bias=False, qk_scale=None, dropout_rate=0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_heads = heads\n",
        "        head_dim = dim // heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(dropout_rate)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = (\n",
        "            self.qkv(x)\n",
        "            .reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
        "            .permute(2, 0, 3, 1, 4)\n",
        "        )\n",
        "        q, k, v = (\n",
        "            qkv[0],\n",
        "            qkv[1],\n",
        "            qkv[2],\n",
        "        )  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale \n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(self.norm(x))\n",
        "\n",
        "\n",
        "class PreNormDrop(nn.Module):\n",
        "    def __init__(self, dim, dropout_rate, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.fn(self.norm(x)))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,  #512\n",
        "        depth,  #4\n",
        "        heads,  #8\n",
        "        mlp_dim,  #4096\n",
        "        dropout_rate=0.1,\n",
        "        attn_dropout_rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers.extend(\n",
        "                [\n",
        "                    Residual(\n",
        "                        PreNormDrop(\n",
        "                            dim,\n",
        "                            dropout_rate,\n",
        "                            SelfAttention(dim, heads=heads, dropout_rate=attn_dropout_rate),\n",
        "                        )\n",
        "                    ),\n",
        "                    Residual(\n",
        "                        PreNorm(dim, FeedForward(dim, mlp_dim, dropout_rate))\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            # dim = dim / 2\n",
        "        self.net = IntermediateSequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "rkdTTtF2GmV5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#from net.IntmdSequential import IntermediateSequential\n",
        "\n",
        "\n",
        "#实现了自注意力机制，相当于unet的bottleneck层\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, dim, heads=8, qkv_bias=False, qk_scale=None, dropout_rate=0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_heads = heads\n",
        "        head_dim = dim // heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(dropout_rate)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = (\n",
        "            self.qkv(x)\n",
        "            .reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
        "            .permute(2, 0, 3, 1, 4)\n",
        "        )\n",
        "        q, k, v = (\n",
        "            qkv[0],\n",
        "            qkv[1],\n",
        "            qkv[2],\n",
        "        )  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale \n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(self.norm(x))\n",
        "\n",
        "\n",
        "class PreNormDrop(nn.Module):\n",
        "    def __init__(self, dim, dropout_rate, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.fn(self.norm(x)))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,  #512\n",
        "        depth,  #4\n",
        "        heads,  #8\n",
        "        mlp_dim,  #4096\n",
        "        dropout_rate=0.1,\n",
        "        attn_dropout_rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers.extend(\n",
        "                [\n",
        "                    Residual(\n",
        "                        PreNormDrop(\n",
        "                            dim,\n",
        "                            dropout_rate,\n",
        "                            SelfAttention(dim, heads=heads, dropout_rate=attn_dropout_rate),\n",
        "                        )\n",
        "                    ),\n",
        "                    Residual(\n",
        "                        PreNorm(dim, FeedForward(dim, mlp_dim, dropout_rate))\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            # dim = dim / 2\n",
        "        self.net = IntermediateSequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "1ANcs0KeG06z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import timeit\n",
        "import copy\n",
        "import numpy as np \n",
        "from torch.nn import ModuleList\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import LeakyReLU\n",
        "#from net.block import *\n",
        "#from net.block import _equalized_conv2d\n",
        "#from net.SGFMT import TransformerModel\n",
        "#from net.PositionalEncoding import FixedPositionalEncoding,LearnedPositionalEncoding\n",
        "#from net.CMSFFT import ChannelTransformer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##权重初始化\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\t\"\"\"\n",
        "\tMSG-Unet-GAN的生成器部分\n",
        "\t\"\"\"\n",
        "\tdef __init__(self,\n",
        "\t\timg_dim=256,\n",
        "\t\tpatch_dim=16,\n",
        "\t\tembedding_dim=512,\n",
        "\t\tnum_channels=3,\n",
        "\t\tnum_heads=8,\n",
        "\t\tnum_layers=4,\n",
        "\t\thidden_dim=256,\n",
        "\t\tdropout_rate=0.0,\n",
        "\t\tattn_dropout_rate=0.0,\n",
        "\t\tin_ch=3, \n",
        "\t\tout_ch=3,\n",
        "\t\tconv_patch_representation=True,\n",
        "\t\tpositional_encoding_type=\"learned\",\n",
        "\t\tuse_eql=True):\n",
        "\t\tsuper(Generator, self).__init__()\n",
        "\t\tassert embedding_dim % num_heads == 0\n",
        "\t\tassert img_dim % patch_dim == 0\n",
        "\n",
        "\t\tself.out_ch=out_ch #输出通道数\n",
        "\t\tself.in_ch=in_ch #输入通道数\n",
        "\t\tself.img_dim = img_dim   #输入图片尺寸\n",
        "\t\tself.embedding_dim = embedding_dim  #512\n",
        "\t\tself.num_heads = num_heads  #多头注意力中头的数量\n",
        "\t\tself.patch_dim = patch_dim  #每个patch的尺寸\n",
        "\t\tself.num_channels = num_channels  #图片通道数?\n",
        "\t\tself.dropout_rate = dropout_rate  #drop-out比率\n",
        "\t\tself.attn_dropout_rate = attn_dropout_rate  #注意力模块的dropout比率\n",
        "\t\tself.conv_patch_representation = conv_patch_representation  #True\n",
        "\n",
        "\t\tself.num_patches = int((img_dim // patch_dim) ** 2)  #将三通道图片分成多少块\n",
        "\t\tself.seq_length = self.num_patches  #每个sequence的长度为patches的大小\n",
        "\t\tself.flatten_dim = 128 * num_channels  #128*3=384\n",
        "\n",
        "        #线性编码\n",
        "\t\tself.linear_encoding = nn.Linear(self.flatten_dim, self.embedding_dim)\n",
        "\t\t#位置编码\n",
        "\t\tif positional_encoding_type == \"learned\":\n",
        "\t\t\tself.position_encoding = LearnedPositionalEncoding(\n",
        "\t\t\t\tself.seq_length, self.embedding_dim, self.seq_length\n",
        "\t\t\t)\n",
        "\t\telif positional_encoding_type == \"fixed\":\n",
        "\t\t\tself.position_encoding = FixedPositionalEncoding(\n",
        "\t\t\t\tself.embedding_dim,\n",
        "\t\t\t)\n",
        "\n",
        "\t\tself.pe_dropout = nn.Dropout(p=self.dropout_rate)\n",
        "\n",
        "\t\tself.transformer = TransformerModel(\n",
        "\t\t\tembedding_dim, #512\n",
        "\t\t\tnum_layers, #4\n",
        "\t\t\tnum_heads,  #8\n",
        "\t\t\thidden_dim,  #4096\n",
        "\n",
        "\t\t\tself.dropout_rate,\n",
        "\t\t\tself.attn_dropout_rate,\n",
        "        )\n",
        "\n",
        "\t\t#layer Norm\n",
        "\t\tself.pre_head_ln = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "\t\tif self.conv_patch_representation:\n",
        "\n",
        "\t\t\tself.Conv_x = nn.Conv2d(\n",
        "\t\t\t\t256,\n",
        "\t\t\t\tself.embedding_dim,  #512\n",
        "\t\t\t\tkernel_size=3,\n",
        "\t\t\t\tstride=1,\n",
        "\t\t\t\tpadding=1\n",
        "\t\t    )\n",
        "\n",
        "\t\tself.bn = nn.BatchNorm2d(256)\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\t\t#modulelist\n",
        "\t\tself.rgb_to_feature=ModuleList([from_rgb(32),from_rgb(64),from_rgb(128)])\n",
        "\t\tself.feature_to_rgb=ModuleList([to_rgb(32),to_rgb(64),to_rgb(128),to_rgb(256)])\n",
        "\n",
        "\t\tself.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\t\tself.Conv1=conv_block(self.in_ch, 16)\n",
        "\t\tself.Conv1_1 = conv_block(16, 32)\n",
        "\t\tself.Conv2 = conv_block(32, 32)\n",
        "\t\tself.Conv2_1 = conv_block(32, 64)\n",
        "\t\tself.Conv3 = conv_block(64,64)\n",
        "\t\tself.Conv3_1 = conv_block(64,128)\n",
        "\t\tself.Conv4 = conv_block(128,128)\n",
        "\t\tself.Conv4_1 = conv_block(128,256)\n",
        "\n",
        "\t\tself.Conv5 = conv_block(512,256)\n",
        "\n",
        "\t\t#self.Conv_x = conv_block(256,512)\n",
        "\t\tself.mtc = ChannelTransformer(channel_num=[32,64,128,256],\n",
        "\t\t\t\t\t\t\t\t\tpatchSize=[32, 16, 8, 4])\n",
        "\t\t\t\t\t\t\t\t\n",
        "\n",
        "\t\tself.Up5 = up_conv(256, 256)\n",
        "\t\tself.coatt5 = CCA(F_g=256, F_x=256)\n",
        "\t\tself.Up_conv5 = conv_block(512, 256)\n",
        "\t\tself.Up_conv5_1 = conv_block(256, 256)\n",
        "\n",
        "\t\tself.Up4 = up_conv(256, 128)\n",
        "\t\tself.coatt4 = CCA(F_g=128, F_x=128)\n",
        "\t\tself.Up_conv4 = conv_block(256, 128)\n",
        "\t\tself.Up_conv4_1 = conv_block(128, 128)\n",
        "\n",
        "\t\tself.Up3 = up_conv(128, 64)\n",
        "\t\tself.coatt3 = CCA(F_g=64, F_x=64)\n",
        "\t\tself.Up_conv3 = conv_block(128, 64)\n",
        "\t\tself.Up_conv3_1 = conv_block(64, 64)\n",
        "\n",
        "\t\tself.Up2 = up_conv(64, 32)\n",
        "\t\tself.coatt2 = CCA(F_g=32, F_x=32)\n",
        "\t\tself.Up_conv2 = conv_block(64, 32)\n",
        "\t\tself.Up_conv2_1 = conv_block(32, 32)\n",
        "\n",
        "\t\tself.Conv = nn.Conv2d(32, self.out_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\t\t# self.active = torch.nn.Sigmoid()\n",
        "\t\t# \n",
        "\tdef reshape_output(self,x): #将transformer的输出resize为原来的特征图尺寸\n",
        "\t\tx = x.view(\n",
        "\t\t\tx.size(0),\n",
        "\t\t\tint(self.img_dim / self.patch_dim),\n",
        "\t\t\tint(self.img_dim / self.patch_dim),\n",
        "\t\t\tself.embedding_dim,\n",
        "\t\t\t)#B,16,16,512\n",
        "\t\tx = x.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t#print(x.shape)\n",
        "\n",
        "\n",
        "\t\toutput=[]\n",
        "\n",
        "\t\tx_1=self.Maxpool(x)\n",
        "\t\tx_2=self.Maxpool(x_1)\n",
        "\t\tx_3=self.Maxpool(x_2)\n",
        "\n",
        "\n",
        "\t\te1 = self.Conv1(x)\n",
        "\t\t#print(e1.shape)\n",
        "\t\te1 = self.Conv1_1(e1)\n",
        "\t\te2 = self.Maxpool1(e1)\n",
        "\t\t#32*128*128\n",
        "\n",
        "\t\tx_1=self.rgb_to_feature[0](x_1)\n",
        "\t\t#e2=torch.cat((x_1,e2), dim=1)\n",
        "\t\te2=x_1+e2\n",
        "\t\te2 = self.Conv2(e2)\n",
        "\t\te2 = self.Conv2_1(e2)\n",
        "\t\te3 = self.Maxpool2(e2)\n",
        "\t\t#64*64*64\n",
        "\n",
        "\t\tx_2=self.rgb_to_feature[1](x_2)\n",
        "\t\t#e3=torch.cat((x_2,e3), dim=1)\n",
        "\t\te3=x_2+e3\n",
        "\t\te3 = self.Conv3(e3)\n",
        "\t\te3 = self.Conv3_1(e3)\n",
        "\t\te4 = self.Maxpool3(e3)\n",
        "\t\t#128*32*32\n",
        "\n",
        "\t\tx_3=self.rgb_to_feature[2](x_3)\n",
        "\t\t#e4=torch.cat((x_3,e4), dim=1)\n",
        "\t\te4=x_3+e4\n",
        "\t\te4 = self.Conv4(e4)\n",
        "\t\te4 = self.Conv4_1(e4)\n",
        "\t\te5 = self.Maxpool4(e4)\n",
        "\t\t#256*16*16\n",
        "\n",
        "\t\t#channel-wise transformer-based attention\n",
        "\t\te1,e2,e3,e4,att_weights = self.mtc(e1,e2,e3,e4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t#spatial-wise transformer-based attention\n",
        "\t\tresidual=e5\n",
        "\t\t#中间的隐变量\n",
        "\t\t#conv_x应该接受256通道，输出512通道的中间隐变量\n",
        "\t\te5= self.bn(e5)\n",
        "\t\te5=self.relu(e5)\n",
        "\t\te5= self.Conv_x(e5) #out->512*16*16 shape->B,512,16,16\n",
        "\t\te5= e5.permute(0, 2, 3, 1).contiguous()  # B,512,16,16->B,16,16,512\n",
        "\t\te5= e5.view(e5.size(0), -1, self.embedding_dim) #B,16,16,512->B,16*16,512 线性映射层\n",
        "\t\te5= self.position_encoding(e5) #位置编码\n",
        "\t\te5= self.pe_dropout(e5)\t #预dropout层\n",
        "\t\t# apply transformer\n",
        "\t\te5= self.transformer(e5)\n",
        "\t\te5= self.pre_head_ln(e5)\t\n",
        "\t\te5= self.reshape_output(e5)#out->512*16*16 shape->B,512,16,16\n",
        "\t\te5=self.Conv5(e5) #out->256,16,16 shape->B,256,16,16\n",
        "\t\t#residual是否要加bn和relu？\n",
        "\t\te5=e5+residual\n",
        "\n",
        "\n",
        "\n",
        "\t\td5 = self.Up5(e5)\n",
        "\t\te4_att = self.coatt5(g=d5, x=e4)\n",
        "\t\td5 = torch.cat((e4_att, d5), dim=1)\n",
        "\t\td5 = self.Up_conv5(d5)\n",
        "\t\td5 = self.Up_conv5_1(d5)\n",
        "\t\t#256\n",
        "\t\tout3=self.feature_to_rgb[3](d5)\n",
        "\t\toutput.append(out3)#32*32orH/8,W/8\n",
        "\n",
        "\t\td4 = self.Up4(d5)\n",
        "\t\te3_att = self.coatt4(g=d4, x=e3)\n",
        "\t\td4 = torch.cat((e3_att, d4), dim=1)\n",
        "\t\td4 = self.Up_conv4(d4)\n",
        "\t\td4 = self.Up_conv4_1(d4)\n",
        "\t\t#128\n",
        "\t\tout2=self.feature_to_rgb[2](d4)\n",
        "\t\toutput.append(out2)#64*64orH/4,W/4\n",
        "\n",
        "\t\td3 = self.Up3(d4)\n",
        "\t\te2_att = self.coatt3(g=d3, x=e2)\n",
        "\t\td3 = torch.cat((e2_att, d3), dim=1)\n",
        "\t\td3 = self.Up_conv3(d3)\n",
        "\t\td3 = self.Up_conv3_1(d3)\n",
        "\t\t#64\n",
        "\t\tout1=self.feature_to_rgb[1](d3)\n",
        "\t\toutput.append(out1)#128#128orH/2,W/2\n",
        "\n",
        "\t\td2 = self.Up2(d3)\n",
        "\t\te1_att = self.coatt2(g=d2, x=e1)\n",
        "\t\td2 = torch.cat((e1_att, d2), dim=1)\n",
        "\t\td2 = self.Up_conv2(d2)\n",
        "\t\td2 = self.Up_conv2_1(d2)\n",
        "\t\t#32\n",
        "\t\tout0=self.feature_to_rgb[0](d2)\n",
        "\t\toutput.append(out0)#256*256\n",
        "\n",
        "\t\t#out = self.Conv(d2)\n",
        "\n",
        "\t\t#d1 = self.active(out)\n",
        "\t\t#output=np.array(output)\n",
        "\t\t\n",
        "\t\treturn output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3,use_eql=True):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.use_eql=use_eql\n",
        "        self.in_channels=in_channels\n",
        "\n",
        "\n",
        "        #modulelist\n",
        "        self.rgb_to_feature1=ModuleList([from_rgb(32),from_rgb(64),from_rgb(128)])\n",
        "        self.rgb_to_feature2=ModuleList([from_rgb(32),from_rgb(64),from_rgb(128)])\n",
        "\n",
        "\n",
        "        self.layer=_equalized_conv2d(self.in_channels*2, 64, (1, 1), bias=True)\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "        self.layer0=DisGeneralConvBlock(64,64,use_eql=self.use_eql)\n",
        "        #128*128*32\n",
        "        \n",
        "        self.layer1=DisGeneralConvBlock(128,128,use_eql=self.use_eql)\n",
        "        #64*64*64\n",
        "        \n",
        "        self.layer2=DisGeneralConvBlock(256,256,use_eql=self.use_eql)\n",
        "        #32*32*128\n",
        "        \n",
        "        self.layer3=DisGeneralConvBlock(512,512,use_eql=self.use_eql)\n",
        "        #16*16*256\n",
        "        \n",
        "        self.layer4=DisFinalBlock(512,use_eql=self.use_eql)\n",
        "        #8*8*512\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, img_A, inputs):\n",
        "    \t#inputs图片尺寸从小到大\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        #img_input = torch.cat((img_A, img_B), 1)\n",
        "        #img_A_128= F.interpolate(img_A, size=[128, 128])\n",
        "        #img_A_64= F.interpolate(img_A, size=[64, 64])\n",
        "        #img_A_32= F.interpolate(img_A, size=[32, 32])\n",
        "\n",
        "\n",
        "        x=torch.cat((img_A[3], inputs[3]), 1)\n",
        "        y = self.pixNorm(self.lrelu(self.layer(x)))\n",
        "        \n",
        "        y=self.layer0(y)\n",
        "        #128*128*64\n",
        "        \n",
        "\n",
        "        x1=self.rgb_to_feature1[0](img_A[2])\n",
        "        x2=self.rgb_to_feature2[0](inputs[2])\n",
        "        x=torch.cat((x1,x2),1)\n",
        "        y=torch.cat((x,y),1)\n",
        "        y=self.layer1(y)\n",
        "        #64*64*128\n",
        "        \n",
        "\n",
        "        x1=self.rgb_to_feature1[1](img_A[1])\n",
        "        x2=self.rgb_to_feature2[1](inputs[1])\n",
        "        x=torch.cat((x1,x2),1)\n",
        "        y=torch.cat((x,y),1)\n",
        "        y=self.layer2(y)\n",
        "        #32*32*256\n",
        "        \n",
        "        x1=self.rgb_to_feature1[2](img_A[0])\n",
        "        x2=self.rgb_to_feature2[2](inputs[0])\n",
        "        x=torch.cat((x1,x2),1)\n",
        "        y=torch.cat((x,y),1)\n",
        "        y=self.layer3(y)\n",
        "        #16*16*512\n",
        "        \n",
        "        y=self.layer4(y)\n",
        "        #8*8*512\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "qR9_2mqVG7oU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch as th\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import timeit\n",
        "import copy\n",
        "import numpy as np \n",
        "from torch.nn import ModuleList\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import LeakyReLU\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#PixelwiseNorm代替了BatchNorm\n",
        "class PixelwiseNorm(th.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PixelwiseNorm, self).__init__()\n",
        "\n",
        "    def forward(self, x, alpha=1e-8):\n",
        "        \"\"\"\n",
        "        forward pass of the module\n",
        "        :param x: input activations volume\n",
        "        :param alpha: small number for numerical stability\n",
        "        :return: y => pixel normalized activations\n",
        "        \"\"\"\n",
        "        y = x.pow(2.).mean(dim=1, keepdim=True).add(alpha).sqrt()  # [N1HW]\n",
        "        y = x / y  # normalize the input x volume\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "class MinibatchStdDev(th.nn.Module):\n",
        "    \"\"\"\n",
        "    Minibatch standard deviation layer for the discriminator\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        derived class constructor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x, alpha=1e-8):\n",
        "        \"\"\"\n",
        "        forward pass of the layer\n",
        "        :param x: input activation volume\n",
        "        :param alpha: small number for numerical stability\n",
        "        :return: y => x appended with standard deviation constant map\n",
        "        \"\"\"\n",
        "        batch_size, _, height, width = x.shape\n",
        "\n",
        "        # [B x C x H x W] Subtract mean over batch.\n",
        "        y = x - x.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # [1 x C x H x W]  Calc standard deviation over batch\n",
        "        y = th.sqrt(y.pow(2.).mean(dim=0, keepdim=False) + alpha)\n",
        "\n",
        "        # [1]  Take average over feature_maps and pixels.\n",
        "        y = y.mean().view(1, 1, 1, 1)\n",
        "\n",
        "        # [B x 1 x H x W]  Replicate over group and pixels.\n",
        "        y = y.repeat(batch_size, 1, height, width)\n",
        "\n",
        "        # [B x C x H x W]  Append as new feature_map.\n",
        "        y = th.cat([x, y], 1)\n",
        "\n",
        "        # return the computed values:\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Equalized learning rate blocks:\n",
        "# extending Conv2D and Deconv2D layers for equalized learning rate logic\n",
        "# ==========================================================\n",
        "class _equalized_conv2d(th.nn.Module):\n",
        "    \"\"\" conv2d with the concept of equalized learning rate\n",
        "        Args:\n",
        "            :param c_in: input channels\n",
        "            :param c_out:  output channels\n",
        "            :param k_size: kernel size (h, w) should be a tuple or a single integer\n",
        "            :param stride: stride for conv\n",
        "            :param pad: padding\n",
        "            :param bias: whether to use bias or not\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, k_size, stride=1, pad=0, bias=True):\n",
        "        \"\"\" constructor for the class \"\"\"\n",
        "        from torch.nn.modules.utils import _pair\n",
        "        from numpy import sqrt, prod\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # define the weight and bias if to be used\n",
        "        self.weight = th.nn.Parameter(th.nn.init.normal_(\n",
        "            th.empty(c_out, c_in, *_pair(k_size))\n",
        "        ))\n",
        "\n",
        "        self.use_bias = bias\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = th.nn.Parameter(th.FloatTensor(c_out).fill_(0))\n",
        "\n",
        "        fan_in = prod(_pair(k_size)) * c_in  # value of fan_in\n",
        "        self.scale = sqrt(2) / sqrt(fan_in)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the network\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import conv2d\n",
        "\n",
        "        return conv2d(input=x,\n",
        "                      weight=self.weight * self.scale,  # scale the weight on runtime\n",
        "                      bias=self.bias if self.use_bias else None,\n",
        "                      stride=self.stride,\n",
        "                      padding=self.pad)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \", \".join(map(str, self.weight.shape))\n",
        "\n",
        "\n",
        "class _equalized_deconv2d(th.nn.Module):\n",
        "    \"\"\" Transpose convolution using the equalized learning rate\n",
        "        Args:\n",
        "            :param c_in: input channels\n",
        "            :param c_out: output channels\n",
        "            :param k_size: kernel size\n",
        "            :param stride: stride for convolution transpose\n",
        "            :param pad: padding\n",
        "            :param bias: whether to use bias or not\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, k_size, stride=1, pad=0, bias=True):\n",
        "        \"\"\" constructor for the class \"\"\"\n",
        "        from torch.nn.modules.utils import _pair\n",
        "        from numpy import sqrt\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # define the weight and bias if to be used\n",
        "        self.weight = th.nn.Parameter(th.nn.init.normal_(\n",
        "            th.empty(c_in, c_out, *_pair(k_size))\n",
        "        ))\n",
        "\n",
        "        self.use_bias = bias\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = th.nn.Parameter(th.FloatTensor(c_out).fill_(0))\n",
        "\n",
        "        fan_in = c_in  # value of fan_in for deconv\n",
        "        self.scale = sqrt(2) / sqrt(fan_in)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the layer\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import conv_transpose2d\n",
        "\n",
        "        return conv_transpose2d(input=x,\n",
        "                                weight=self.weight * self.scale,  # scale the weight on runtime\n",
        "                                bias=self.bias if self.use_bias else None,\n",
        "                                stride=self.stride,\n",
        "                                padding=self.pad)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \", \".join(map(str, self.weight.shape))\n",
        "\n",
        "\n",
        "\n",
        "#basic block of the encoding part of the genarater\n",
        "#编码器的基本卷积块\n",
        "class conv_block(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution Block \n",
        "    with two convolution layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch,use_eql=True):\n",
        "        super(conv_block, self).__init__()\n",
        "        \n",
        "        if use_eql:\n",
        "            self.conv_1=  _equalized_conv2d(in_ch, out_ch, (1, 1),\n",
        "                                            pad=0, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_3 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "\n",
        "        else:\n",
        "            self.conv_1 = Conv2d(in_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(out_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import interpolate\n",
        "\n",
        "        #y = interpolate(x, scale_factor=2)\n",
        "        y=self.conv_1(self.lrelu(self.pixNorm(x)))\n",
        "        residual=y\n",
        "        y=self.conv_2(self.lrelu(self.pixNorm(y)))\n",
        "        y=self.conv_3(self.lrelu(self.pixNorm(y)))\n",
        "        y=y+residual\n",
        "\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#basic up convolution block of the encoding part of the genarater\n",
        "#编码器的基本卷积块\n",
        "class up_conv(nn.Module):\n",
        "    \"\"\"\n",
        "    Up Convolution Block\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch,use_eql=True):\n",
        "        super(up_conv, self).__init__()\n",
        "        if use_eql:\n",
        "            self.conv_1=  _equalized_conv2d(in_ch, out_ch, (1, 1),\n",
        "                                            pad=0, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_3 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "\n",
        "        else:\n",
        "            self.conv_1 = Conv2d(in_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(out_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import interpolate\n",
        "\n",
        "        x = interpolate(x, scale_factor=2, mode=\"bilinear\")\n",
        "        y=self.conv_1(self.lrelu(self.pixNorm(x)))\n",
        "        residual=y\n",
        "        y=self.conv_2(self.lrelu(self.pixNorm(y)))\n",
        "        y=self.conv_3(self.lrelu(self.pixNorm(y)))        \n",
        "        y=y+residual\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#判别器的最后一层\n",
        "class DisFinalBlock(th.nn.Module):\n",
        "    \"\"\" Final block for the Discriminator \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, use_eql=True):\n",
        "        \"\"\"\n",
        "        constructor of the class\n",
        "        :param in_channels: number of input channels\n",
        "        :param use_eql: whether to use equalized learning rate\n",
        "        \"\"\"\n",
        "        from torch.nn import LeakyReLU\n",
        "        from torch.nn import Conv2d\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # declare the required modules for forward pass\n",
        "        self.batch_discriminator = MinibatchStdDev()\n",
        "\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(in_channels + 1, in_channels, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(in_channels, in_channels, (4, 4),stride=2,pad=1,\n",
        "                                            bias=True)\n",
        "\n",
        "            # final layer emulates the fully connected layer\n",
        "            self.conv_3 = _equalized_conv2d(in_channels, 1, (1, 1), bias=True)\n",
        "\n",
        "        else:\n",
        "            # modules required:\n",
        "            self.conv_1 = Conv2d(in_channels + 1, in_channels, (3, 3), padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(in_channels, in_channels, (4, 4), bias=True)\n",
        "\n",
        "            # final conv layer emulates a fully connected layer\n",
        "            self.conv_3 = Conv2d(in_channels, 1, (1, 1), bias=True)\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the FinalBlock\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        # minibatch_std_dev layer\n",
        "        y = self.batch_discriminator(x)\n",
        "\n",
        "        # define the computations\n",
        "        y = self.lrelu(self.conv_1(y))\n",
        "        y = self.lrelu(self.conv_2(y))\n",
        "\n",
        "        # fully connected layer\n",
        "        y = self.conv_3(y)  # This layer has linear activation\n",
        "\n",
        "        # flatten the output raw discriminator scores\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "#判别器基本卷积块\n",
        "class DisGeneralConvBlock(th.nn.Module):\n",
        "    \"\"\" General block in the discriminator  \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, use_eql=True):\n",
        "        \"\"\"\n",
        "        constructor of the class\n",
        "        :param in_channels: number of input channels\n",
        "        :param out_channels: number of output channels\n",
        "        :param use_eql: whether to use equalized learning rate\n",
        "        \"\"\"\n",
        "        from torch.nn import AvgPool2d, LeakyReLU\n",
        "        from torch.nn import Conv2d\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(in_channels, in_channels, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(in_channels, out_channels, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "        else:\n",
        "            # convolutional modules\n",
        "            self.conv_1 = Conv2d(in_channels, in_channels, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(in_channels, out_channels, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "\n",
        "        self.downSampler = AvgPool2d(2)  # downsampler\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the module\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        # define the computations\n",
        "        y = self.lrelu(self.conv_1(x))\n",
        "        y = self.lrelu(self.conv_2(y))\n",
        "        y = self.downSampler(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "class from_rgb(nn.Module):\n",
        "    \"\"\"\n",
        "    The RGB image is transformed into a multi-channel feature map to be concatenated with \n",
        "    the feature map with the same number of channels in the network\n",
        "    把RGB图转换为多通道特征图，以便与网络中相同通道数的特征图拼接\n",
        "    \"\"\"\n",
        "    def __init__(self, outchannels, use_eql=True):\n",
        "        super(from_rgb, self).__init__()\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(3, outchannels, (1, 1), bias=True)\n",
        "        else:\n",
        "            self.conv_1 = nn.Conv2d(3, outchannels, (1, 1),bias=True)\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        y = self.pixNorm(self.lrelu(self.conv_1(x)))\n",
        "        return y\n",
        "\n",
        "class to_rgb(nn.Module):\n",
        "    \"\"\"\n",
        "    把多通道特征图转换为RGB三通道图，以便输入判别器\n",
        "    The multi-channel feature map is converted into RGB image for input to the discriminator\n",
        "    \"\"\"\n",
        "    def __init__(self, inchannels, use_eql=True):\n",
        "        super(to_rgb, self).__init__()\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(inchannels, 3, (1, 1), bias=True)\n",
        "        else:\n",
        "            self.conv_1 = nn.Conv2d(inchannels, 3, (1, 1),bias=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "\n",
        "        y = self.conv_1(x)\n",
        "\n",
        "        return y\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "\n",
        "\n",
        "class CCA(nn.Module):\n",
        "    \"\"\"\n",
        "    CCA Block\n",
        "    \"\"\"\n",
        "    def __init__(self, F_g, F_x):\n",
        "        super().__init__()\n",
        "        self.mlp_x = nn.Sequential(\n",
        "            Flatten(),\n",
        "            nn.Linear(F_x, F_x))\n",
        "        self.mlp_g = nn.Sequential(\n",
        "            Flatten(),\n",
        "            nn.Linear(F_g, F_x))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        # channel-wise attention\n",
        "        avg_pool_x = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "        channel_att_x = self.mlp_x(avg_pool_x)\n",
        "        avg_pool_g = F.avg_pool2d( g, (g.size(2), g.size(3)), stride=(g.size(2), g.size(3)))\n",
        "        channel_att_g = self.mlp_g(avg_pool_g)\n",
        "        channel_att_sum = (channel_att_x + channel_att_g)/2.0\n",
        "        scale = th.sigmoid(channel_att_sum).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        x_after_channel = x * scale\n",
        "        out = self.relu(x_after_channel)\n",
        "        return out"
      ],
      "metadata": {
        "id": "NHu2M53DHFSm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "#from skimage.measure.simple_metrics import compare_psnr\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "def weights_init_kaiming(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n",
        "        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n",
        "        nn.init.constant(m.bias.data, 0.0)\n",
        "\n",
        "class VGG19_PercepLoss(nn.Module):\n",
        "    \"\"\" Calculates perceptual loss in vgg19 space\n",
        "    \"\"\"\n",
        "    def __init__(self, _pretrained_=True):\n",
        "        super(VGG19_PercepLoss, self).__init__()\n",
        "        self.vgg = models.vgg19(pretrained=_pretrained_).features\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad_(False)\n",
        "\n",
        "    def get_features(self, image, layers=None):\n",
        "        if layers is None: \n",
        "            layers = {'30': 'conv5_2'} # may add other layers\n",
        "        features = {}\n",
        "        x = image\n",
        "        for name, layer in self.vgg._modules.items():\n",
        "            x = layer(x)\n",
        "            if name in layers:\n",
        "                features[layers[name]] = x\n",
        "        return features\n",
        "\n",
        "    def forward(self, pred, true, layer='conv5_2'):\n",
        "        true_f = self.get_features(true)\n",
        "        pred_f = self.get_features(pred)\n",
        "        return torch.mean((true_f[layer]-pred_f[layer])**2)\n",
        "\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])\n",
        "\n",
        "def data_augmentation(image, mode):\n",
        "    out = np.transpose(image, (1,2,0))\n",
        "    #out = image\n",
        "    if mode == 0:\n",
        "        # original\n",
        "        out = out\n",
        "    elif mode == 1:\n",
        "        # flip up and down\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 2:\n",
        "        # rotate counterwise 90 degree\n",
        "        out = np.rot90(out)\n",
        "    elif mode == 3:\n",
        "        # rotate 90 degree and flip up and down\n",
        "        out = np.rot90(out)\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 4:\n",
        "        # rotate 180 degree\n",
        "        out = np.rot90(out, k=2)\n",
        "    elif mode == 5:\n",
        "        # rotate 180 degree and flip\n",
        "        out = np.rot90(out, k=2)\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 6:\n",
        "        # rotate 270 degree\n",
        "        out = np.rot90(out, k=3)\n",
        "    elif mode == 7:\n",
        "        # rotate 270 degree and flip\n",
        "        out = np.rot90(out, k=3)\n",
        "        out = np.flipud(out)\n",
        "    return np.transpose(out, (2,0,1))\n",
        "    #return out"
      ],
      "metadata": {
        "id": "VQoWmzsfHVfd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "def ssim(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "metadata": {
        "id": "rn9wy3xHHcB5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "def ssim(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "metadata": {
        "id": "Qse-tOL4IAAQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import itertools\n",
        "\"\"\"\n",
        "Qnt: Quantization Methods. this collection of methods, compute the quantization tables  for RGB, and LAB color space. \n",
        "These methods are organized in a way that each bin is recognized by its central value.\n",
        "ES: RGB 0-255\n",
        "    2 levels of quantization for each channel\n",
        "    0-127:128-255. these two intervals are represented as 63.5 and 191.5 in the table.\n",
        "    then, only for RGB, the values are normalized in 0-1 range\n",
        "    \n",
        "    For L and AB the methods provide in output the 2D and 1D quantization tables. The values are not normalized.\n",
        "\"\"\"\n",
        "def quantRGB(bins,vmax=255,vmin=0):\n",
        "    a = torch.linspace(vmin+((vmax-vmin)/(bins*2)), vmax-((vmax-vmin)/(bins*2)), bins)\n",
        "    mat=torch.cartesian_prod(a,a,a)/vmax\n",
        "    return mat.view(1,bins**3,3,1,1)\n",
        "\n",
        "def quantL(bins,vmax,vmin):\n",
        "    a = torch.linspace(vmin+((vmax-vmin)/(bins*2)), vmax-((vmax-vmin)/(bins*2)), bins)\n",
        "    mat = a\n",
        "    return mat.view(1,bins,1,1)\n",
        "\n",
        "\n",
        "def quantAB(bins, vmax,vmin):\n",
        "    a = torch.linspace(vmin+((vmax-vmin)/(bins*2)), vmax-((vmax-vmin)/(bins*2)), bins)\n",
        "    mat=torch.cartesian_prod(a,a)\n",
        "    return mat.view(1,bins**2,2,1,1)"
      ],
      "metadata": {
        "id": "m4i0b--EIOZo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "FcPex4ATIx8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "84308382-1add-4b38-9116-6c2232b664d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.3) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#from utility import ptcolor as ptcolor\n",
        "\"\"\"\n",
        "Relu_Softmax_LAB: This collections of methods compute the softmax (on channel L or AB) using the principles:\n",
        "high value for taller bins and very low values for shorter bins ( almost 0 everywhere).\n",
        "\"\"\"\n",
        "\n",
        "def softquant(x, vmin, vmax, bins):\n",
        "    slope = (bins - 1) / (vmax - vmin)\n",
        "    a = torch.linspace(vmin, vmax, bins, device=x.device)\n",
        "    diff = (x.unsqueeze(-1) - a).abs()\n",
        "    return torch.nn.functional.relu(1 - diff * slope) #high value for taller bins, everywhere else almost 0\n",
        "\n",
        "def softhist_L(x, vmin, vmax, bins):\n",
        "    x = torch.clamp(x, vmin, vmax)\n",
        "    q = softquant(x, vmin, vmax, bins)\n",
        "    return q.view(x.size(0), -1, bins).mean(1)\n",
        "\n",
        "\n",
        "def softhist_AB(lab, vmax, bins):\n",
        "    a = torch.clamp(lab[:, 1, :, :], -vmax, vmax)\n",
        "    b = torch.clamp(lab[:, 2, :, :], -vmax, vmax)\n",
        "    qa = softquant(a, -vmax, vmax, bins).to(device=lab.device)\n",
        "    qb = softquant(b, -vmax, vmax, bins).to(lab.device)\n",
        "    return torch.einsum(\"bijc,bijd->bcd\", qa, qb).to(lab.device) / (a.size(1) * a.size(2))\n",
        "\n",
        "#ptcolor.py\n",
        "def _t(data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "# Helper for color matrix multiplication\n",
        "def _mul(coeffs, image):\n",
        "    coeffs = coeffs.to(image.device).view(3, 3, 1, 1)\n",
        "    return torch.nn.functional.conv2d(image, coeffs)\n",
        "\n",
        "\n",
        "_RGB_TO_XYZ = {\n",
        "    \"srgb\": _t([[0.4124564, 0.3575761, 0.1804375],\n",
        "                [0.2126729, 0.7151522, 0.0721750],\n",
        "                [0.0193339, 0.1191920, 0.9503041]]),\n",
        "\n",
        "    \"prophoto\": _t([[0.7976749, 0.1351917, 0.0313534],\n",
        "                    [0.2880402, 0.7118741, 0.0000857],\n",
        "                    [0.0000000, 0.0000000, 0.8252100]])\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "_XYZ_TO_RGB = {\n",
        "    \"srgb\": _t([[3.2404542, -1.5371385, -0.4985314],\n",
        "                   [-0.9692660, 1.8760108, 0.0415560],\n",
        "                   [0.0556434, -0.2040259, 1.0572252]]),\n",
        "\n",
        "    \"prophoto\": _t([[ 1.3459433, -0.2556075, -0.0511118],\n",
        "                    [-0.5445989,  1.5081673,  0.0205351],\n",
        "                    [0.0000000,  0.0000000,  1.2118128]])\n",
        "    }\n",
        "\n",
        "\n",
        "WHITE_POINTS = {item[0]: _t(item[1:]).view(1, 3, 1, 1) for item in [\n",
        "    (\"a\", 1.0985, 1.0000, 0.3558),\n",
        "    (\"b\", 0.9807, 1.0000, 1.1822),\n",
        "    (\"e\", 1.0000, 1.0000, 1.0000),\n",
        "    (\"d50\", 0.9642, 1.0000, 0.8251),\n",
        "    (\"d55\", 0.9568, 1.0000, 0.9214),\n",
        "    (\"d65\", 0.9504, 1.0000, 1.0888),\n",
        "    (\"icc\", 0.9642, 1.0000, 0.8249)\n",
        "]}\n",
        "\n",
        "\n",
        "_EPSILON = 0.008856\n",
        "_KAPPA = 903.3\n",
        "_XYZ_TO_LAB = _t([[0.0, 116.0, 0.], [500.0, -500.0, 0.], [0.0, 200.0, -200.0]])\n",
        "_LAB_TO_XYZ = _t([[1.0 / 116.0, 1.0 / 500.0, 0], [1.0 / 116.0, 0, 0], [1.0 / 116.0, 0, -1.0 / 200.0]])\n",
        "_LAB_OFF = _t([16.0, 0.0, 0.0]).view(1, 3, 1, 1)\n",
        "\n",
        "\n",
        "def apply_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Linear to gamma rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> apply_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 0.5).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.0031308\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, 12.92 * rgb, (1.055 * torch.pow(torch.abs(rgb1), 1 / 2.4) - 0.055))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        return torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), 1.0 / gamma)\n",
        "\n",
        "\n",
        "\n",
        "def remove_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Gamma to linear rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> remove_gamma(apply_gamma(torch.tensor([0.001, 0.3, 0.4])))\n",
        "    tensor([0.0010,  0.3000,  0.4000])\n",
        "    >>> remove_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 2.0).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.04045\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, rgb / 12.92, torch.pow(torch.abs(rgb1 + 0.055) / 1.055, 2.4))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        res = torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), gamma) + \\\n",
        "              torch.min(rgb, rgb.new_tensor(0.0)) # very important to avoid vanishing gradients\n",
        "        return res\n",
        "\n",
        "\n",
        "def rgb2xyz(rgb, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to XYZ conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> rgb2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> rgb2xyz(torch.tensor([0., 0.75, 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.1868,  0.3737,  0.0623])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None).view(-1)\n",
        "    tensor([0.4871,  0.6716,  0.2931])\n",
        "    >>> rgb2xyz(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None, space='prophoto').view(-1)\n",
        "    tensor([0.4335,  0.6847,  0.1650])\n",
        "    \"\"\"\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = remove_gamma(rgb, gamma_correction)\n",
        "    return _mul(_RGB_TO_XYZ[space], rgb)\n",
        "\n",
        "\n",
        "def xyz2rgb(xyz, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"XYZ to sRGB conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2rgb(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2rgb(torch.tensor([0.04, 0.02, 0.05]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.3014,  0.0107,  0.2503])\n",
        "    >>> xyz2rgb(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    \"\"\"\n",
        "    rgb = _mul(_XYZ_TO_RGB[space], xyz)\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = apply_gamma(rgb, gamma_correction)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def _lab_f(x):\n",
        "    x1 = torch.max(x, x.new_tensor(_EPSILON))\n",
        "    return torch.where(x > _EPSILON, torch.pow(x1, 1.0 / 3), (_KAPPA * x + 16.0) / 116.0)\n",
        "\n",
        "\n",
        "def xyz2lab(xyz, white_point=\"d65\"):\n",
        "    \"\"\"XYZ to Lab conversion.\n",
        "    xyz: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2lab(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2lab(torch.tensor([0.4, 0.2, 0.1]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([51.8372,  82.3018,  26.7245])\n",
        "    >>> xyz2lab(torch.tensor([1., 1., 1.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([100., 0., 0.])\n",
        "    \"\"\"\n",
        "    xyz = xyz / WHITE_POINTS[white_point].to(xyz.device)\n",
        "    f_xyz = _lab_f(xyz)\n",
        "    return _mul(_XYZ_TO_LAB, f_xyz) - _LAB_OFF.to(xyz.device)\n",
        "\n",
        "\n",
        "def _inv_lab_f(x):\n",
        "    x3 = torch.max(x, x.new_tensor(_EPSILON)) ** 3\n",
        "    return torch.where(x3 > _EPSILON, x3, (116.0 * x - 16.0) / _KAPPA)\n",
        "\n",
        "\n",
        "def lab2xyz(lab, white_point=\"d65\"):\n",
        "    \"\"\"lab to XYZ conversion.\n",
        "    lab: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> lab2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> lab2xyz(torch.tensor([100., 0., 0.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([1.,  1.,  1.])\n",
        "    >>> lab2xyz(torch.tensor([50., 25., -30.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.2254,  0.1842,  0.4046])\n",
        "    \"\"\"\n",
        "    f_xyz = _mul(_LAB_TO_XYZ, lab + _LAB_OFF.to(lab.device))\n",
        "    xyz = _inv_lab_f(f_xyz)\n",
        "    return xyz * WHITE_POINTS[white_point].to(lab.device)\n",
        "\n",
        "\n",
        "def rgb2lab(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to Lab conversion.\"\"\"\n",
        "    lab = xyz2lab(rgb2xyz(rgb, gamma_correction, clip_rgb, space), white_point)\n",
        "    return lab\n",
        "\n",
        "\n",
        "def lab2rgb(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"Lab to sRGB conversion.\"\"\"\n",
        "    return xyz2rgb(lab2xyz(rgb, white_point), gamma_correction, clip_rgb, space)\n",
        "\n",
        "def lab2lch(lab):\n",
        "    \"\"\"Lab to LCH conversion.\"\"\"\n",
        "    l = lab[:, 0, :, :]\n",
        "    c = torch.norm(lab[:, 1:, :, :], 2, 1)\n",
        "    h = torch.atan2(lab[:, 2, :, :], lab[:, 1, :, :])\n",
        "    h = h * (180 / 3.141592653589793)\n",
        "    h = torch.where(h >= 0, h, 360 + h)\n",
        "    return torch.stack([l, c, h], 1)\n",
        "\n",
        "\n",
        "def rgb2lch(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to LCH conversion.\"\"\"\n",
        "    lab = rgb2lab(rgb, white_point, gamma_correction, clip_rgb, space)\n",
        "    return lab2lch(lab)\n",
        "\n",
        "def squared_deltaE(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    return torch.sum((lab1 - lab2) ** 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def deltaE(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE(lab1, lab2).item()\n",
        "    75.0\n",
        "    \"\"\"\n",
        "    return torch.norm(lab1 - lab2, 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def squared_deltaE94(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    diff_2 = (lab1 - lab2) ** 2\n",
        "    dl_2 = diff_2[:, 0:1, :, :]\n",
        "    c1 = torch.norm(lab1[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    c2 = torch.norm(lab2[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    dc_2 = (c1 - c2) ** 2\n",
        "    dab_2 = torch.sum(diff_2[:, 1:3, :, :], 1, keepdim=True)\n",
        "    dh_2 = torch.abs(dab_2 - dc_2)\n",
        "    de_2 = (dl_2 +\n",
        "            dc_2 / ((1 + 0.045 * c1) ** 2) +\n",
        "            dh_2 / ((1 + 0.015 * c1) ** 2))\n",
        "    return de_2\n",
        "\n",
        "\n",
        "def deltaE94(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([80., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 20., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 10.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    6.8966\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    54.7575\n",
        "    \"\"\"\n",
        "    # The ReLU prevents from NaNs in gradient computation\n",
        "    sq = torch.nn.functional.relu(squared_deltaE94(lab1, lab2))\n",
        "    return torch.sqrt(sq)\n",
        "\n",
        "\n",
        "def _check_conversion(**opts):\n",
        "    \"\"\"Verify the conversions on the RGB cube.\n",
        "    >>> _check_conversion(white_point='d65', gamma_correction='srgb', clip_rgb=False, space='srgb')\n",
        "    True\n",
        "    >>> _check_conversion(white_point='d50', gamma_correction=1.8, clip_rgb=False, space='prophoto')\n",
        "    True\n",
        "    \"\"\"\n",
        "    for r in range(0, 256, 15):\n",
        "        for g in range(0, 256, 15):\n",
        "            for b in range(0, 256, 15):\n",
        "                rgb = torch.tensor([r / 255.0, g / 255.0, b / 255.0]).view(1, 3, 1, 1)\n",
        "                lab = rgb2lab(rgb, **opts)\n",
        "                rgb2 = lab2rgb(lab, **opts)\n",
        "                de = deltaE(rgb, rgb2).item()\n",
        "                if de > 2e-4:\n",
        "                    print(\"Conversion failed for RGB:\", r, g, b, \" deltaE\", de)\n",
        "                    return False\n",
        "    return True\n",
        "#ptcolor.end\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    im = torch.randn([1,3,64,64])\n",
        "    lab = rgb2lab(im)\n",
        "    for c in (0, 1, 2):\n",
        "        print(lab[:, c, :, :].min(), lab[:, c, :, :].max())\n",
        "    hist_l = softhist_L(lab[:, 0, :, :], 0, 100, 50)\n",
        "    print(hist_l.shape)\n",
        "    hist_ab = softhist_AB(lab, 80, 20)\n",
        "    plt.plot(hist_l[0].numpy())\n",
        "    plt.figure()\n",
        "    plt.imshow(hist_ab[0].numpy())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YkyMAQpYIb0A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "ba403059-e9d6-4c53-b762-c053664c300e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-192.8673) tensor(247.3076)\n",
            "tensor(-288.7970) tensor(526.7705)\n",
            "tensor(-330.5036) tensor(448.8473)\n",
            "torch.Size([1, 50])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQiElEQVR4nO3df4wU533H8ffn7vhRY/wDExP/oI6VIksoqmmEsK24Fa4TG5BlkshKQVVLWkvnRrHUSI0qmkpxlP6TqHKttlh2SIIgVWK7dUuCFGJAbiXHkp34bOEfJKZQRGTOBGrjYtzEhju+/ePmqnuW3WNmZ+d2dv15SehmZ56deWbn+DCz82UeRQRmZpMGut0BM6sXh4KZJRwKZpZwKJhZwqFgZomhbnegmdmaE3M1L19j3zypjipr3HW5e6sa7NdA/j5cct27udq9Ofou77x1pumKaxkKczWPG4duz9U2xsbyr7iqA5z3tm4dfsGU/+RQBX4Zi6y3kCJ9KEB5j8XgYP6VVnR7X78xN3fbOx/fn6vd1+96vuUyXz6YWaJUKEhaJWm/pIOSNjZZPkfSY9nyn0j6UJntmVn12g4FSYPAg8BqYCmwXtLShmZ3A29FxG8BDwBfb3d7ZjYzypwprAAORsShiDgNPAqsbWizFtiWTT8O3KrcF3Nm1g1lQuEq4LUpr49k85q2iYgx4CRwWbOVSRqWNCJp5Ey8V6JbZlZGbb5ojIjNEbE8IpbP0pxud8fsfatMKIwCi6e8vjqb17SNpCHgYuDNEts0s4qVCYXngCWSrpU0G1gH7GhoswPYkE3fBfx7+P9qm9Va28VLETEm6V5gFzAIbImIfZK+CoxExA7g28A/SToInGAiOMysxlTHf7gv0oK4Qbd2uxtWlapuQBWpqoyznV9nDQxetiBXu2dOPM7JM8ebHoje2mMzq5xDwcwSDgUzSzgUzCzhUDCzhEPBzBIOBTNLOBTMLOFQMLOEQ8HMErV8cKtVqEiJcZES+IECDzgtIm85ctG2VayzqpLoIn3I+yDjaY6tzxTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSZUaIWizpPyT9TNI+SX/epM1KSScl7c3+fLlcd82samWKl8aAv4iIFyTNB56XtCciftbQ7scRcUeJ7ZjZDGr7TCEijkbEC9n0KeDnnDtClJn1mI6UOWejSf8O8JMmi2+S9CLwOvDFiNjXYh3DwDDAXC7oRLfePyp7OnKRkugKSox7TR0+g/HxnA1blzmXDgVJFwL/CnwhIt5uWPwCcE1EvCNpDfB9YEnTLkZsBjbDxCPey/bLzNpT6u6DpFlMBMJ3I+LfGpdHxNsR8U42vROYJWlhmW2aWbXK3H0QEyNA/Twi/q5Fmw9ODj0vaUW2PY8laVZjZS4fPgb8EfCypL3ZvC8BvwkQEQ8zMX7k5ySNAb8G1nksSbN6KzOW5NPAtN9ERcQmYFO72zCzmeeKRjNLOBTMLOFQMLOEQ8HMEg4FM0v4ac7WWpGnE9ehxLcKRe6gV1VuXkDkfppz60U+UzCzhEPBzBIOBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws0R9KxrzVof16zNbalAdV4sqxV46vnXo69mcx2yavvpMwcwSDgUzS5QOBUmHJb2cDQs30mS5JP2DpIOSXpL00bLbNLPqdOo7hVsi4o0Wy1YzMdbDEuAG4KHsp5nV0ExcPqwFvhMTngUukXTFDGzXzNrQiVAIYLek57Oh3xpdBbw25fURmow5KWlY0oikkTO814FumVk7OnH5cHNEjEq6HNgj6dWIeKroSjxsnFk9lD5TiIjR7OdxYDuwoqHJKLB4yuurs3lmVkNlx5KcJ2n+5DRwG/BKQ7MdwB9ndyFuBE5GxNEy2zWz6pS9fFgEbM+GixwCvhcRT0j6M/j/oeN2AmuAg8CvgD8puU0zq1CpUIiIQ8D1TeY/PGU6gM+X2U7t1aEkOa+qHsbaYw847VsDOY/vNMfAFY1mlnAomFnCoWBmCYeCmSUcCmaWcCiYWcKhYGYJh4KZJRwKZpZwKJhZor5Pc86rqpLZKp7MW1WJcRFnx/O3LfLZVnUciqy3Dk9TzqsOn1cLPlMws4RDwcwSDgUzSzgUzCzhUDCzhEPBzBIOBTNLtB0Kkq7Lhoqb/PO2pC80tFkp6eSUNl8u32Uzq1LbxUsRsR9YBiBpkInHtm9v0vTHEXFHu9sxs5nVqcuHW4H/iohfdGh9ZtYlnSpzXgc80mLZTZJeBF4HvhgR+5o1yoacGwaYywX5S4KrKgfupScO16G8t6qnORcqDS9Qwt1tVX1eeZ/mPN0qyq5A0mzgTuBfmix+AbgmIq4H/hH4fqv1RMTmiFgeEctnMadst8ysTZ24fFgNvBARxxoXRMTbEfFONr0TmCVpYQe2aWYV6UQorKfFpYOkDyobPkrSimx7b3Zgm2ZWkVLfKWTjR34CuGfKvKlDxt0FfE7SGPBrYF02YpSZ1VTZYeP+F7isYd7UIeM2AZvKbMPMZpYrGs0s4VAws4RDwcwSDgUzSzgUzCzR+09z7iV1KMmuwx3hIn3odulyHZ4WXqBtnD6dc5Wt1+kzBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSDgUzSzgUzCxRzzJngQbylZcWqoIt9GTgAiXJ3S4drkMpbhG91t/3GZ8pmFkiVyhI2iLpuKRXpsxbIGmPpAPZz0tbvHdD1uaApA2d6riZVSPvmcJWYFXDvI3AkxGxBHgye52QtAC4D7gBWAHc1yo8zKwecoVCRDwFnGiYvRbYlk1vAz7Z5K23A3si4kREvAXs4dxwMbMaKfOdwqKIOJpN/xJY1KTNVcBrU14fyeaZWU115IvGbCyHUl/9ShqWNCJp5Ey814lumVkbyoTCMUlXAGQ/jzdpMwosnvL66mzeOZKxJOWxJM26pUwo7AAm7yZsAH7QpM0u4DZJl2ZfMN6WzTOzmsp7S/IR4BngOklHJN0NfA34hKQDwMez10haLulbABFxAvgb4Lnsz1ezeWZWU6rj0I4XDSyIG4duz9U2xguUNLqisft9hd6qaOylvgKak+/S+9n3fsTbZ99sunP1LHOeqHPO2bZAKFT1NOUq1OEvelV9qEMw5dVLfQU0lO+vtE63PrYuczazhEPBzBIOBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSNS1zroFu19HXoby218qnjRgby9dums/VZwpmlnAomFnCoWBmCYeCmSUcCmaWcCiYWcKhYGaJ84ZCi3Ek/1bSq5JekrRd0iUt3ntY0suS9koa6WTHzawaec4UtnLuUG97gI9ExG8D/wn81TTvvyUilkXE8va6aGYz6byh0GwcyYjYHRGTpVPPMjHIi5n1gU6UOf8p8FiLZQHslhTANyJic6uVSBoGhgHmcgEMVPRo7X7ksmGbdLb88S0VCpL+GhgDvtuiyc0RMSrpcmCPpFezM49zZIGxGeCigcv8m2vWJW3ffZD0WeAO4A+jxf+uiIjR7OdxYDuwot3tmdnMaCsUJK0C/hK4MyJ+1aLNPEnzJ6eZGEfylWZtzaw+8tySbDaO5CZgPhOXBHslPZy1vVLSzuyti4CnJb0I/BT4YUQ8UclemFnHnPc7hYhY32T2t1u0fR1Yk00fAq4v1Tszm3GuaDSzhEPBzBIOBTNLOBTMLOFQMLNELZ/mLAkNDuZqO91TaWunSF+LlC73ml46ZnVQ4HdBs/L9ldZY63X6TMHMEg4FM0s4FMws4VAws4RDwcwSDgUzSzgUzCzhUDCzhEPBzBK1rGgEequir5f6WpU6fAb9Wik5w5WwPlMws4RDwcwS7Q4b9xVJo9nzGfdKWtPivask7Zd0UNLGTnbczKrR7rBxAA9kw8Eti4idjQslDQIPAquBpcB6SUvLdNbMqtfWsHE5rQAORsShiDgNPAqsbWM9ZjaDynyncG826vQWSZc2WX4V8NqU10eyeU1JGpY0ImnkdLxboltmVka7ofAQ8GFgGXAUuL9sRyJic0Qsj4jlszW37OrMrE1thUJEHIuI8Yg4C3yT5sPBjQKLp7y+OptnZjXW7rBxV0x5+SmaDwf3HLBE0rWSZgPrgB3tbM/MZs55KxqzYeNWAgslHQHuA1ZKWsbEUPOHgXuytlcC34qINRExJuleYBcwCGyJiH2V7IWZdYzq+ODTi4cWxk0X5rtRMX7qVP4VV7Wv3S7xreEx7Jgin20/fw45Dcyfn6vds+/s4OT4G00/XFc0mlnCoWBmCYeCmSUcCmaWcCiYWcKhYGYJh4KZJRwKZpZwKJhZwqFgZomaPs1ZMFCDpwPnVUV5bZHy3jqUAlfVh6qeZNxLJdEzXEbvMwUzSzgUzCzhUDCzhEPBzBIOBTNLOBTMLOFQMLNEnmc0bgHuAI5HxEeyeY8B12VNLgH+JyKWNXnvYeAUMA6MRcTyDvXbzCqSp3hpK7AJ+M7kjIj4g8lpSfcDJ6d5/y0R8Ua7HTSzmXXeUIiIpyR9qNkySQI+A/x+Z7tlZt1Stsz5d4FjEXGgxfIAdksK4BsRsbnViiQNA8MAcwcuhKEKKrC7/dTlflaHcuQq+lCHcugCfdBgzq8Jp9n/sn/z1gOPTLP85ogYlXQ5sEfSq9mAtefIAmMzwMWzPlCDI2H2/tT23QdJQ8CngcdatYmI0ezncWA7zYeXM7MaKXNL8uPAqxFxpNlCSfMkzZ+cBm6j+fByZlYj5w2FbNi4Z4DrJB2RdHe2aB0Nlw6SrpS0M3u5CHha0ovAT4EfRsQTneu6mVUhz92H9S3mf7bJvNeBNdn0IeD6kv0zsxnmikYzSzgUzCzhUDCzhEPBzBIOBTNL1PJpzkuWnmLnridztV295GO516vBwdxtY3w8d9tKFCmvLbBfnD2bv+1AgX8zqvq8iuzbmTP52+bctyK/BypSvl1kvwr8Lhz40tJc7d79+10tl/lMwcwSDgUzSzgUzCzhUDCzhEPBzBIOBTNLOBTMLOFQMLOEQ8HMEg4FM0so6vC02gaS/hv4RcPshUA/jh/Rr/sF/btv/bBf10TEB5otqGUoNCNppB9HmOrX/YL+3bd+3a9Jvnwws4RDwcwSvRQKLUeX6nH9ul/Qv/vWr/sF9NB3CmY2M3rpTMHMZoBDwcwSPREKklZJ2i/poKSN3e5Pp0g6LOllSXsljXS7P2VI2iLpuKRXpsxbIGmPpAPZz0u72cd2tNivr0gazY7bXklrutnHTqt9KEgaBB4EVgNLgfWS8j2IrjfcEhHL+uC+91ZgVcO8jcCTEbEEeDJ73Wu2cu5+ATyQHbdlEbGzyfKeVftQYGKk6oMRcSgiTgOPAmu73CdrEBFPAScaZq8FtmXT24BPzminOqDFfvW1XgiFq4DXprw+ks3rBwHslvS8pOFud6YCiyLiaDb9SyYGHe4X90p6Kbu86LnLoun0Qij0s5sj4qNMXBp9XtLvdbtDVYmJe9/9cv/7IeDDwDLgKHB/d7vTWb0QCqPA4imvr87m9byIGM1+Hge2M3Gp1E+OSboCIPt5vMv96YiIOBYR4xFxFvgmfXbceiEUngOWSLpW0mxgHbCjy30qTdI8SfMnp4HbgFemf1fP2QFsyKY3AD/oYl86ZjLoMp+iz45bLUeImioixiTdC+wCBoEtEbGvy93qhEXA9mxUoSHgexHxRHe71D5JjwArgYWSjgD3AV8D/lnS3Uz8V/jPdK+H7WmxXyslLWPicugwcE/XOlgBlzmbWaIXLh/MbAY5FMws4VAws4RDwcwSDgUzSzgUzCzhUDCzxP8BY2+fYIpc+jQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\"\"\"\n",
        "Five K Dataset: \n",
        "    constructor params: \n",
        "        -list_file: path of a file with the list of images\n",
        "        -raw_dir: path of the directory which contains raw images\n",
        "        -expert_dir: path of the directory which contains expert images\n",
        "        -training: if True, horizontal flip is applied\n",
        "        -size: if is not None, resize is applied\n",
        "        -filenames, if is true, __getitem__ returns also the name of the image taken  \n",
        "\"\"\"\n",
        "\n",
        "class FiveKDataset(data.Dataset):\n",
        "    def __init__(self, list_file, raw_dir, expert_dir, training, size=None, filenames=False):\n",
        "        join = os.path.join\n",
        "        self.file_list = []\n",
        "        with open(list_file) as f:\n",
        "            for line in f:\n",
        "                name = line.strip()\n",
        "                if name:\n",
        "                    p = (join(raw_dir, name), join(expert_dir, name), name)\n",
        "                    self.file_list.append(p)\n",
        "        self.filenames = filenames\n",
        "        transformation=[]\n",
        "        if size is not None:\n",
        "          transformation.append(transforms.Resize((size,size)))\n",
        "        if training:\n",
        "          transformation.append(transforms.RandomHorizontalFlip(0.5))\n",
        "        transformation.append(transforms.ToTensor())\n",
        "        self.transform=transforms.Compose(transformation)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "   # def __getitem__(self, index):\n",
        "    #    raw = Image.open(self.file_list[index][0])\n",
        "     #   expert =  Image.open(self.file_list[index][1])\n",
        "      #  raw_exp = self.transform(torch.stack([raw, expert]))\n",
        "       # if self.filenames:\n",
        "        #    return raw_exp[0],raw_exp[1], self.file_list[index][2]\n",
        "        #else:\n",
        "         #   return raw_exp[0],raw_exp[1]\n",
        "\n",
        "\n",
        "def _test():\n",
        "    train_list = \"/content/test1.txt\"\n",
        "    raw_dir = \"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test1\"\n",
        "    expert_dir = \"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test1\"\n",
        "    dataset = FiveKDataset(train_list, raw_dir, expert_dir, True, None)\n",
        "    loader = torch.utils.data.DataLoader(dataset, 10, shuffle=True,num_workers=16)\n",
        "    for raw, expert in loader:\n",
        "        print(raw.size(), expert.size())\n",
        "\n",
        "\n",
        "\n",
        "def _test():\n",
        "    train_list = \"/content/train1.txt\"\n",
        "    raw_dir = \"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/train1\"\n",
        "    expert_dir = \"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/train1\"\n",
        "    dataset = FiveKDataset(train_list, raw_dir, expert_dir, True, None)\n",
        "    loader = torch.utils.data.DataLoader(dataset, 10, shuffle=True)\n",
        "    #for raw, expert in loader:\n",
        "     #   print(raw.size(), expert.size())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _test()"
      ],
      "metadata": {
        "id": "8AkK6axoKQuz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "if __name__ != \"__main__\":\n",
        "    matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_plots(data, height, width, dpi=100.0, rgbonly=False):\n",
        "    n = data.shape[1]\n",
        "    x = np.linspace(0, 1, n)\n",
        "    fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
        "    plt.grid()\n",
        "    styles = [\"r-\", \"g-\", \"b-\", \"c-\", \"m-\", \"y-\", \"k-\"]\n",
        "    if rgbonly:\n",
        "        styles = styles[:3]\n",
        "    for y, style in zip(data, styles):\n",
        "        plt.plot(x, y, style, lw=2)\n",
        "    ax = plt.gca()\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    plt.tick_params(axis='both', which='both', labelbottom=False,\n",
        "                    labelleft=False)\n",
        "    fig.tight_layout(pad=0)\n",
        "    fig.canvas.draw()\n",
        "    bin = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "    w, h = fig.canvas.get_width_height()\n",
        "    plt.close()\n",
        "    return bin.reshape([h, w, 3])\n",
        "\n",
        "\n",
        "def make_test_image(samples, batch_size):\n",
        "    a = np.linspace(0, 1, samples, dtype=np.float32)\n",
        "    z = np.zeros_like(a)\n",
        "    im = np.stack([a, z, z,\n",
        "                   z, a, z,\n",
        "                   z, z, a,\n",
        "                   z, a, a,\n",
        "                   a, z, a,\n",
        "                   a, a, z,\n",
        "                   a, a, a])\n",
        "    im = im.reshape([7, 3, samples])\n",
        "    im = im.transpose([1, 0, 2])\n",
        "    im = np.tile(im[None, :], [batch_size, 1, 1, 1])\n",
        "    return im\n",
        "\n",
        "\n",
        "def plots_from_test_image(im, height, width, rgbonly=False):\n",
        "    channels = [im[:, 0, 0, :],\n",
        "                im[:, 1, 1, :],\n",
        "                im[:, 2, 2, :]]\n",
        "    channels.append((channels[1] + channels[2]) / 2)\n",
        "    channels.append((channels[0] + channels[2]) / 2)\n",
        "    channels.append((channels[0] + channels[1]) / 2)\n",
        "    channels.append((channels[0] + channels[1] + channels[2]) / 3)\n",
        "    im = np.stack(channels, 1)\n",
        "    n = im.shape[0]\n",
        "    pls = [make_plots(im[i, :], height, width, rgbonly=rgbonly) for i in range(n)]\n",
        "    return np.stack(pls, 0).transpose([0, 3, 1, 2]) / 255.0\n",
        "\n",
        "\n",
        "def _main():\n",
        "    data = np.outer(np.arange(3, 10), np.arange(11)) / 60.0\n",
        "    # data = np.random.rand(7, 10)\n",
        "    im = make_plots(data, 256, 256)\n",
        "    print(im.shape, im.dtype)\n",
        "    plt.imshow(im)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    _main()"
      ],
      "metadata": {
        "id": "x0Bd_GvkKRu7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "384934a1-111c-4d6b-8a0f-9f7bad7e0bb9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3) uint8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils\n",
        "import os,sys\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Helper for the creation of module-global constant tensors\n",
        "def _t(data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "# Helper for color matrix multiplication\n",
        "def _mul(coeffs, image):\n",
        "    coeffs = coeffs.to(image.device).view(3, 3, 1, 1)\n",
        "    return torch.nn.functional.conv2d(image, coeffs)\n",
        "\n",
        "\n",
        "_RGB_TO_XYZ = {\n",
        "    \"srgb\": _t([[0.4124564, 0.3575761, 0.1804375],\n",
        "                [0.2126729, 0.7151522, 0.0721750],\n",
        "                [0.0193339, 0.1191920, 0.9503041]]),\n",
        "\n",
        "    \"prophoto\": _t([[0.7976749, 0.1351917, 0.0313534],\n",
        "                    [0.2880402, 0.7118741, 0.0000857],\n",
        "                    [0.0000000, 0.0000000, 0.8252100]])\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "_XYZ_TO_RGB = {\n",
        "    \"srgb\": _t([[3.2404542, -1.5371385, -0.4985314],\n",
        "                   [-0.9692660, 1.8760108, 0.0415560],\n",
        "                   [0.0556434, -0.2040259, 1.0572252]]),\n",
        "\n",
        "    \"prophoto\": _t([[ 1.3459433, -0.2556075, -0.0511118],\n",
        "                    [-0.5445989,  1.5081673,  0.0205351],\n",
        "                    [0.0000000,  0.0000000,  1.2118128]])\n",
        "    }\n",
        "\n",
        "\n",
        "WHITE_POINTS = {item[0]: _t(item[1:]).view(1, 3, 1, 1) for item in [\n",
        "    (\"a\", 1.0985, 1.0000, 0.3558),\n",
        "    (\"b\", 0.9807, 1.0000, 1.1822),\n",
        "    (\"e\", 1.0000, 1.0000, 1.0000),\n",
        "    (\"d50\", 0.9642, 1.0000, 0.8251),\n",
        "    (\"d55\", 0.9568, 1.0000, 0.9214),\n",
        "    (\"d65\", 0.9504, 1.0000, 1.0888),\n",
        "    (\"icc\", 0.9642, 1.0000, 0.8249)\n",
        "]}\n",
        "\n",
        "\n",
        "_EPSILON = 0.008856\n",
        "_KAPPA = 903.3\n",
        "_XYZ_TO_LAB = _t([[0.0, 116.0, 0.], [500.0, -500.0, 0.], [0.0, 200.0, -200.0]])\n",
        "_LAB_TO_XYZ = _t([[1.0 / 116.0, 1.0 / 500.0, 0], [1.0 / 116.0, 0, 0], [1.0 / 116.0, 0, -1.0 / 200.0]])\n",
        "_LAB_OFF = _t([16.0, 0.0, 0.0]).view(1, 3, 1, 1)\n",
        "\n",
        "\n",
        "def apply_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Linear to gamma rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> apply_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 0.5).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.0031308\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, 12.92 * rgb, (1.055 * torch.pow(torch.abs(rgb1), 1 / 2.4) - 0.055))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        return torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), 1.0 / gamma)\n",
        "\n",
        "\n",
        "\n",
        "def remove_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Gamma to linear rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> remove_gamma(apply_gamma(torch.tensor([0.001, 0.3, 0.4])))\n",
        "    tensor([0.0010,  0.3000,  0.4000])\n",
        "    >>> remove_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 2.0).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.04045\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, rgb / 12.92, torch.pow(torch.abs(rgb1 + 0.055) / 1.055, 2.4))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        res = torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), gamma) + \\\n",
        "              torch.min(rgb, rgb.new_tensor(0.0)) # very important to avoid vanishing gradients\n",
        "        return res\n",
        "\n",
        "\n",
        "def rgb2xyz(rgb, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to XYZ conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> rgb2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> rgb2xyz(torch.tensor([0., 0.75, 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.1868,  0.3737,  0.0623])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None).view(-1)\n",
        "    tensor([0.4871,  0.6716,  0.2931])\n",
        "    >>> rgb2xyz(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None, space='prophoto').view(-1)\n",
        "    tensor([0.4335,  0.6847,  0.1650])\n",
        "    \"\"\"\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = remove_gamma(rgb, gamma_correction)\n",
        "    return _mul(_RGB_TO_XYZ[space], rgb)\n",
        "\n",
        "\n",
        "def xyz2rgb(xyz, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"XYZ to sRGB conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2rgb(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2rgb(torch.tensor([0.04, 0.02, 0.05]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.3014,  0.0107,  0.2503])\n",
        "    >>> xyz2rgb(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    \"\"\"\n",
        "    rgb = _mul(_XYZ_TO_RGB[space], xyz)\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = apply_gamma(rgb, gamma_correction)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def _lab_f(x):\n",
        "    x1 = torch.max(x, x.new_tensor(_EPSILON))\n",
        "    return torch.where(x > _EPSILON, torch.pow(x1, 1.0 / 3), (_KAPPA * x + 16.0) / 116.0)\n",
        "\n",
        "\n",
        "def xyz2lab(xyz, white_point=\"d65\"):\n",
        "    \"\"\"XYZ to Lab conversion.\n",
        "    xyz: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2lab(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2lab(torch.tensor([0.4, 0.2, 0.1]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([51.8372,  82.3018,  26.7245])\n",
        "    >>> xyz2lab(torch.tensor([1., 1., 1.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([100., 0., 0.])\n",
        "    \"\"\"\n",
        "    xyz = xyz / WHITE_POINTS[white_point].to(xyz.device)\n",
        "    f_xyz = _lab_f(xyz)\n",
        "    return _mul(_XYZ_TO_LAB, f_xyz) - _LAB_OFF.to(xyz.device)\n",
        "\n",
        "\n",
        "def _inv_lab_f(x):\n",
        "    x3 = torch.max(x, x.new_tensor(_EPSILON)) ** 3\n",
        "    return torch.where(x3 > _EPSILON, x3, (116.0 * x - 16.0) / _KAPPA)\n",
        "\n",
        "\n",
        "def lab2xyz(lab, white_point=\"d65\"):\n",
        "    \"\"\"lab to XYZ conversion.\n",
        "    lab: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> lab2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> lab2xyz(torch.tensor([100., 0., 0.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([1.,  1.,  1.])\n",
        "    >>> lab2xyz(torch.tensor([50., 25., -30.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.2254,  0.1842,  0.4046])\n",
        "    \"\"\"\n",
        "    f_xyz = _mul(_LAB_TO_XYZ, lab + _LAB_OFF.to(lab.device))\n",
        "    xyz = _inv_lab_f(f_xyz)\n",
        "    return xyz * WHITE_POINTS[white_point].to(lab.device)\n",
        "\n",
        "\n",
        "def rgb2lab(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to Lab conversion.\"\"\"\n",
        "    lab = xyz2lab(rgb2xyz(rgb, gamma_correction, clip_rgb, space), white_point)\n",
        "    return lab\n",
        "\n",
        "\n",
        "def lab2rgb(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"Lab to sRGB conversion.\"\"\"\n",
        "    return xyz2rgb(lab2xyz(rgb, white_point), gamma_correction, clip_rgb, space)\n",
        "\n",
        "def lab2lch(lab):\n",
        "    \"\"\"Lab to LCH conversion.\"\"\"\n",
        "    l = lab[:, 0, :, :]\n",
        "    c = torch.norm(lab[:, 1:, :, :], 2, 1)\n",
        "    h = torch.atan2(lab[:, 2, :, :], lab[:, 1, :, :])\n",
        "    h = h * (180 / 3.141592653589793)\n",
        "    h = torch.where(h >= 0, h, 360 + h)\n",
        "    return torch.stack([l, c, h], 1)\n",
        "\n",
        "\n",
        "def rgb2lch(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to LCH conversion.\"\"\"\n",
        "    lab = rgb2lab(rgb, white_point, gamma_correction, clip_rgb, space)\n",
        "    return lab2lch(lab)\n",
        "\n",
        "def squared_deltaE(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    return torch.sum((lab1 - lab2) ** 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def deltaE(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE(lab1, lab2).item()\n",
        "    75.0\n",
        "    \"\"\"\n",
        "    return torch.norm(lab1 - lab2, 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def squared_deltaE94(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    diff_2 = (lab1 - lab2) ** 2\n",
        "    dl_2 = diff_2[:, 0:1, :, :]\n",
        "    c1 = torch.norm(lab1[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    c2 = torch.norm(lab2[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    dc_2 = (c1 - c2) ** 2\n",
        "    dab_2 = torch.sum(diff_2[:, 1:3, :, :], 1, keepdim=True)\n",
        "    dh_2 = torch.abs(dab_2 - dc_2)\n",
        "    de_2 = (dl_2 +\n",
        "            dc_2 / ((1 + 0.045 * c1) ** 2) +\n",
        "            dh_2 / ((1 + 0.015 * c1) ** 2))\n",
        "    return de_2\n",
        "\n",
        "\n",
        "def deltaE94(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([80., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 20., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 10.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    6.8966\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    54.7575\n",
        "    \"\"\"\n",
        "    # The ReLU prevents from NaNs in gradient computation\n",
        "    sq = torch.nn.functional.relu(squared_deltaE94(lab1, lab2))\n",
        "    return torch.sqrt(sq)\n",
        "\n",
        "\n",
        "def _check_conversion(**opts):\n",
        "    \"\"\"Verify the conversions on the RGB cube.\n",
        "    >>> _check_conversion(white_point='d65', gamma_correction='srgb', clip_rgb=False, space='srgb')\n",
        "    True\n",
        "    >>> _check_conversion(white_point='d50', gamma_correction=1.8, clip_rgb=False, space='prophoto')\n",
        "    True\n",
        "    \"\"\"\n",
        "    for r in range(0, 256, 15):\n",
        "        for g in range(0, 256, 15):\n",
        "            for b in range(0, 256, 15):\n",
        "                rgb = torch.tensor([r / 255.0, g / 255.0, b / 255.0]).view(1, 3, 1, 1)\n",
        "                lab = rgb2lab(rgb, **opts)\n",
        "                rgb2 = lab2rgb(lab, **opts)\n",
        "                de = deltaE(rgb, rgb2).item()\n",
        "                if de > 2e-4:\n",
        "                    print(\"Conversion failed for RGB:\", r, g, b, \" deltaE\", de)\n",
        "                    return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def _check_gradients():\n",
        "    \"\"\"Verify some borderline gradient computation\n",
        "    >>> a = torch.zeros(1, 3, 1, 1, requires_grad=True)\n",
        "    >>> b = torch.zeros(1, 3, 1, 1, requires_grad=True)\n",
        "    >>> deltaE(a, b).backward()\n",
        "    >>> torch.any(torch.isnan(a.grad)).item()\n",
        "    0\n",
        "    >>> torch.any(torch.isnan(b.grad)).item()\n",
        "    0\n",
        "    >>> deltaE94(a, b).backward()\n",
        "    >>> torch.any(torch.isnan(a.grad)).item()\n",
        "    0\n",
        "    >>> torch.any(torch.isnan(b.grad)).item()\n",
        "    0\n",
        "    \"\"\"\n",
        "    return True\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import doctest\n",
        "    doctest.testmod(optionflags=doctest.NORMALIZE_WHITESPACE)\n",
        "    print(\"Test completed\")"
      ],
      "metadata": {
        "id": "4obanjblKV5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2d52f7-c3bd-4133-b900-40ac97472dfa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/doctest.py\", line 1487, in run\n",
            "    sys.settrace(save_trace)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import collections\n",
        "\n",
        "\n",
        "class Display:\n",
        "    \"\"\"Write on terminal statistics in a fancy way.\n",
        "    Colors are used to signal variations in the data.\n",
        "    Example:\n",
        "    \n",
        "    display = Display(\"Step {step}/{}   loss: {loss:.2f}\")\n",
        "    display.disp(10, 100, loss=3.14159)\n",
        "    It would print the message:\n",
        "    Step 10/100    loss 3.14\n",
        "    with \"3.14\" colored according to historical variation of the loss\n",
        "    value.\n",
        "    Named fields (such as \"loss\") are tracked and displayed in color.\n",
        "    Unnamed fields are not tracked.  \"step\" is a special untracked field,\n",
        "    and \"steps_s\" is a tracked field that is automatically computed.\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, format_string):\n",
        "        \"\"\"Create the display object.\n",
        "        The format string encodes how information should be displayed.\n",
        "        \"\"\"\n",
        "        self.fmt = format_string\n",
        "        self.vars_ = collections.defaultdict(_DisplayVar)\n",
        "        self.steps_s = _DisplayVar()\n",
        "        self.last_step = None\n",
        "        self.last_time = None\n",
        "\n",
        "    def message(self, step, *fields, **data):\n",
        "        \"\"\"Compose a message with the given information.\"\"\"\n",
        "        self._update_steps_s(step)\n",
        "        d = dict((k, self._update_var(k, v)) for (k, v) in data.items())\n",
        "        return self.fmt.format(*fields, step=step, steps_s=self.steps_s, **d)\n",
        "        \n",
        "    def disp(self, step, *fields, **data):\n",
        "        \"\"\"Print on stdout the given information according the the format of the display.\"\"\"\n",
        "        print(self.message(step, *fields, **data))\n",
        "\n",
        "    def _update_var(self, k, v):\n",
        "        dv = self.vars_[k]\n",
        "        dv.add(v)\n",
        "        return dv\n",
        "\n",
        "    def _update_steps_s(self, step):\n",
        "        tm = time.perf_counter()\n",
        "        if self.last_step is None or self.last_time >= tm:\n",
        "            speed = float(\"nan\")\n",
        "        else:\n",
        "            speed = (step - self.last_step) / (tm - self.last_time)\n",
        "        self.last_time = tm\n",
        "        self.last_step = step\n",
        "        self.steps_s.add(speed)\n",
        "\n",
        "\n",
        "class _DisplayVar:\n",
        "    \"\"\"Track the history of a value and format its last value accordingly.\"\"\"\n",
        "\n",
        "    # Ansi codes for colors and styles\n",
        "    MIN = \"\\x1B[1;32m\"    # bold green\n",
        "    LOW = \"\\x1B[0;32m\"    # green\n",
        "    NORMAL = \"\\x1B[0;33m\" # yellow\n",
        "    HIGH = \"\\x1B[0;31m\"   # red\n",
        "    MAX = \"\\x1B[1;31m\"    # bold red\n",
        "    NAN = \"\\x1B[1;36m\"    # cyan\n",
        "    RESET = \"\\x1B[0m\"     # default style\n",
        "    \n",
        "    def __init__(self, history_len=10):\n",
        "        \"\"\"Initialize the object.\n",
        "        Remembers up to history_len values.\n",
        "        \"\"\"\n",
        "        self.history = collections.deque(maxlen=history_len)\n",
        "        self.minval = self.maxval = None\n",
        "        self.lastvalue = float(\"nan\")\n",
        "        self.state = self.NAN\n",
        "        \n",
        "    def add(self, value):\n",
        "        \"\"\"Add a new value to the series.\"\"\"\n",
        "        self.lastvalue = value\n",
        "        if math.isnan(value):\n",
        "            self.state = self.NAN\n",
        "        elif not self.history:\n",
        "            self.state = self.NORMAL\n",
        "            self.history.append(value)\n",
        "            self.minval = self.maxval = value\n",
        "        else:\n",
        "            _, s = min((min(self.history), self.NORMAL), (value, self.LOW))\n",
        "            _, s = max((max(self.history), s), (value, self.HIGH))\n",
        "            self.maxval, _, s = max((self.maxval, 1, s), (value, 0, self.MAX))\n",
        "            self.minval, _, s = min((self.minval, 0, s), (value, 1, self.MIN))\n",
        "            self.state = s\n",
        "            self.history.append(value)\n",
        "\n",
        "    def __format__(self, spec):\n",
        "        \"\"\"Format the last added value.\"\"\"\n",
        "        s = self.lastvalue.__format__(spec)\n",
        "        return self.state + s + self.RESET\n",
        "    \n",
        "\n",
        "def _demo():\n",
        "    import random\n",
        "    fmt = \"Step: {step:3d}/{}  Loss: {loss:6.3f}  {steps_s:6.4f} steps/s\"\n",
        "    display = Display(fmt)\n",
        "    for step in range(1, 101):\n",
        "        time.sleep(1)\n",
        "        display.disp(step, 100, loss=random.random() * 100)\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    _demo()\n",
        "    # session = Session(\"model_dir\", save_every=100, save_count=5, state=[model, optimizer], max_epocs=3)\n",
        "    # session.add_state(model)\n",
        "    # session.add_state(optimizer)\n",
        "    # session.restore()\n",
        "    # for x ,y in session.train_loop(loader):\n",
        "    #     session.step\n",
        "    #     session.epoc"
      ],
      "metadata": {
        "id": "TPe1h-hRKhqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcc17cb-6aaf-45d1-9a06-d1e9d8fe2b5a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:   1/100  Loss: \u001b[0;33m34.908\u001b[0m  \u001b[1;36m   nan\u001b[0m steps/s\n",
            "Step:   2/100  Loss: \u001b[1;31m80.505\u001b[0m  \u001b[0;33m0.9979\u001b[0m steps/s\n",
            "Step:   3/100  Loss: \u001b[0;33m58.538\u001b[0m  \u001b[1;31m0.9980\u001b[0m steps/s\n",
            "Step:   4/100  Loss: \u001b[1;31m96.274\u001b[0m  \u001b[1;31m0.9980\u001b[0m steps/s\n",
            "Step:   5/100  Loss: \u001b[1;32m 7.364\u001b[0m  \u001b[1;31m0.9987\u001b[0m steps/s\n",
            "Step:   6/100  Loss: \u001b[0;33m27.467\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:   7/100  Loss: \u001b[1;31m99.897\u001b[0m  \u001b[1;31m0.9988\u001b[0m steps/s\n",
            "Step:   8/100  Loss: \u001b[0;33m42.141\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:   9/100  Loss: \u001b[0;33m87.440\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  10/100  Loss: \u001b[0;33m17.401\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  11/100  Loss: \u001b[0;33m15.679\u001b[0m  \u001b[0;33m0.9985\u001b[0m steps/s\n",
            "Step:  12/100  Loss: \u001b[1;32m 6.522\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  13/100  Loss: \u001b[1;32m 3.116\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  14/100  Loss: \u001b[0;33m81.512\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  15/100  Loss: \u001b[0;33m25.903\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  16/100  Loss: \u001b[0;33m67.678\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  17/100  Loss: \u001b[0;33m22.440\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  18/100  Loss: \u001b[0;33m17.955\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  19/100  Loss: \u001b[0;33m 5.900\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  20/100  Loss: \u001b[0;33m24.537\u001b[0m  \u001b[0;33m0.9986\u001b[0m steps/s\n",
            "Step:  21/100  Loss: \u001b[0;33m69.853\u001b[0m  \u001b[1;31m0.9988\u001b[0m steps/s\n",
            "Step:  22/100  Loss: \u001b[0;33m32.757\u001b[0m  \u001b[1;32m0.9979\u001b[0m steps/s\n",
            "Step:  23/100  Loss: \u001b[0;33m31.632\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  24/100  Loss: \u001b[0;31m86.129\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  25/100  Loss: \u001b[0;33m43.489\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  26/100  Loss: \u001b[0;33m 7.784\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  27/100  Loss: \u001b[0;33m 7.498\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  28/100  Loss: \u001b[0;33m42.055\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  29/100  Loss: \u001b[0;31m87.932\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  30/100  Loss: \u001b[0;33m80.791\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  31/100  Loss: \u001b[0;33m15.198\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  32/100  Loss: \u001b[0;33m71.596\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  33/100  Loss: \u001b[0;31m90.847\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  34/100  Loss: \u001b[0;33m88.780\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  35/100  Loss: \u001b[0;33m73.107\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  36/100  Loss: \u001b[0;33m74.944\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  37/100  Loss: \u001b[0;33m39.530\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  38/100  Loss: \u001b[0;33m52.206\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  39/100  Loss: \u001b[0;33m26.100\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  40/100  Loss: \u001b[0;33m55.956\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  41/100  Loss: \u001b[0;33m15.615\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  42/100  Loss: \u001b[0;33m50.437\u001b[0m  \u001b[1;31m0.9988\u001b[0m steps/s\n",
            "Step:  43/100  Loss: \u001b[0;33m40.155\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  44/100  Loss: \u001b[0;33m64.169\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  45/100  Loss: \u001b[0;33m66.913\u001b[0m  \u001b[1;32m0.9977\u001b[0m steps/s\n",
            "Step:  46/100  Loss: \u001b[0;33m25.999\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  47/100  Loss: \u001b[0;31m89.609\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  48/100  Loss: \u001b[0;31m94.687\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  49/100  Loss: \u001b[0;33m17.170\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  50/100  Loss: \u001b[0;33m44.674\u001b[0m  \u001b[1;31m0.9996\u001b[0m steps/s\n",
            "Step:  51/100  Loss: \u001b[0;33m39.206\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  52/100  Loss: \u001b[0;33m21.024\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  53/100  Loss: \u001b[0;33m86.110\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  54/100  Loss: \u001b[0;31m97.174\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  55/100  Loss: \u001b[0;31m99.117\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  56/100  Loss: \u001b[0;33m81.563\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  57/100  Loss: \u001b[0;32m15.799\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  58/100  Loss: \u001b[0;32m 3.522\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  59/100  Loss: \u001b[0;33m81.466\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  60/100  Loss: \u001b[0;33m 8.276\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  61/100  Loss: \u001b[0;33m83.904\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  62/100  Loss: \u001b[0;33m97.116\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  63/100  Loss: \u001b[0;33m64.868\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  64/100  Loss: \u001b[0;33m63.495\u001b[0m  \u001b[0;32m0.9980\u001b[0m steps/s\n",
            "Step:  65/100  Loss: \u001b[0;33m50.452\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  66/100  Loss: \u001b[0;33m34.483\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  67/100  Loss: \u001b[0;33m18.787\u001b[0m  \u001b[0;33m0.9985\u001b[0m steps/s\n",
            "Step:  68/100  Loss: \u001b[1;31m99.936\u001b[0m  \u001b[0;31m0.9990\u001b[0m steps/s\n",
            "Step:  69/100  Loss: \u001b[1;32m 0.796\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  70/100  Loss: \u001b[0;33m63.293\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  71/100  Loss: \u001b[0;33m25.636\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  72/100  Loss: \u001b[0;33m97.963\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  73/100  Loss: \u001b[0;33m95.837\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  74/100  Loss: \u001b[0;33m15.457\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  75/100  Loss: \u001b[0;33m63.478\u001b[0m  \u001b[0;33m0.9990\u001b[0m steps/s\n",
            "Step:  76/100  Loss: \u001b[0;33m79.755\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  77/100  Loss: \u001b[0;33m66.888\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  78/100  Loss: \u001b[0;33m48.852\u001b[0m  \u001b[0;32m0.9981\u001b[0m steps/s\n",
            "Step:  79/100  Loss: \u001b[0;33m42.008\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  80/100  Loss: \u001b[0;33m31.590\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  81/100  Loss: \u001b[0;32m 8.706\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  82/100  Loss: \u001b[0;33m32.058\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  83/100  Loss: \u001b[0;33m11.196\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  84/100  Loss: \u001b[0;31m86.600\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  85/100  Loss: \u001b[0;32m 5.584\u001b[0m  \u001b[0;32m0.9977\u001b[0m steps/s\n",
            "Step:  86/100  Loss: \u001b[0;33m79.774\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  87/100  Loss: \u001b[0;33m25.058\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  88/100  Loss: \u001b[0;33m58.922\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  89/100  Loss: \u001b[0;33m32.345\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  90/100  Loss: \u001b[0;33m67.748\u001b[0m  \u001b[0;33m0.9986\u001b[0m steps/s\n",
            "Step:  91/100  Loss: \u001b[0;33m86.107\u001b[0m  \u001b[0;33m0.9979\u001b[0m steps/s\n",
            "Step:  92/100  Loss: \u001b[0;33m57.768\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  93/100  Loss: \u001b[0;33m67.806\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  94/100  Loss: \u001b[0;33m30.026\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  95/100  Loss: \u001b[0;31m97.856\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  96/100  Loss: \u001b[0;32m13.254\u001b[0m  \u001b[0;33m0.9986\u001b[0m steps/s\n",
            "Step:  97/100  Loss: \u001b[0;33m55.439\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  98/100  Loss: \u001b[0;33m50.712\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  99/100  Loss: \u001b[0;32m 1.771\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step: 100/100  Loss: \u001b[0;33m37.723\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K15QrEksOhuv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SplineInterpolator(torch.nn.Module):\n",
        "    \"\"\"Module performing spline interpolation.\n",
        "    Splines are defined by a set of n nodes.  x coordinates of the\n",
        "    nodes are assumed to be equispaced in the [0, 1] range.\n",
        "    y coordinates of the nodes are part of the input.\n",
        "    Given a different set of x coordinates, the module compute\n",
        "    the interpolated y coordinates.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, nodes, dtype=torch.float32):\n",
        "        \"\"\"Create the object.\n",
        "        Parameters\n",
        "        ----------\n",
        "        nodes : int\n",
        "            number of nodes.\n",
        "        dtype\n",
        "            type of internal data.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        A = self._precalc(nodes)\n",
        "        self.register_buffer(\"A\", torch.tensor(A, dtype=dtype))\n",
        "\n",
        "    def _precalc(self, n):\n",
        "        # Helper function computing the internal matrix A.\n",
        "        h = 1.0 / (n - 1)\n",
        "        mat = 4 * np.eye(n - 2)        \n",
        "        np.fill_diagonal(mat[1:, :-1], 1)\n",
        "        np.fill_diagonal(mat[:-1, 1:], 1)\n",
        "        A = 6 * np.linalg.inv(mat) / (h ** 2)\n",
        "        z = np.zeros(n - 2)\n",
        "        A = np.vstack([z, A, z])\n",
        "\n",
        "        B = np.zeros([n - 2, n])\n",
        "        np.fill_diagonal(B, 1)\n",
        "        np.fill_diagonal(B[:, 1:], -2)\n",
        "        np.fill_diagonal(B[:, 2:], 1)\n",
        "        A = np.dot(A, B)\n",
        "        return A.T\n",
        "        \n",
        "    def _coefficients(self, y):\n",
        "        # Helper function computing the coefficients of the polynomials\n",
        "        # For the given y coordinates of the nodes.\n",
        "        n = self.A.size(1)\n",
        "        h = 1.0 / (n - 1)\n",
        "        M = torch.mm(y, self.A)\n",
        "        a = (M[:, 1:] - M[:, :-1]) / (6 * h)\n",
        "        b = M[:, :-1] / 2\n",
        "        c = (y[:, 1:] - y[:, :-1]) / h - (M[:, 1:] + 2 * M[:, :-1]) * (h / 6)\n",
        "        return (a, b, c, y[:, :-1])\n",
        "\n",
        "    def _apply(self, x, coeffs):\n",
        "        # Helper function interpolating the splines at x.\n",
        "        # coeffs is the list of coefficients of the polynomials.\n",
        "        n = self.A.size(1)\n",
        "        xv = x.view(x.size(0), -1)\n",
        "        xi = torch.clamp(xv * (n - 1), 0, n - 2).long()\n",
        "        xf = xv - xi.float() / (n - 1)\n",
        "        a, b, c, d = (torch.gather(cc, 1, xi) for cc in coeffs)\n",
        "        z = d + c * xf + b * (xf ** 2) + a * (xf ** 3)\n",
        "        return z.view_as(x)\n",
        "\n",
        "    def forward(self, y, x):\n",
        "        \"\"\"Interpolate values using splines.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : tensor (b, n)\n",
        "            y coordinates for the nodes (one set for each batch).\n",
        "        x : tensor (b, m1, m2, ..., md)\n",
        "            values to interpolats (one set for each batch).\n",
        "        Returns\n",
        "        -------\n",
        "        tensor (b, m1, m2, ..., md)\n",
        "            interpolated values.\n",
        "        \"\"\"\n",
        "        return self._apply(x, self._coefficients(y))\n",
        "\n",
        "    \n",
        "def _demo():\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = 10\n",
        "    b = 5\n",
        "    sp = SplineInterpolator(n)\n",
        "    y = torch.rand((b, n))\n",
        "    x = torch.rand((b, 20 * n, 10))\n",
        "    z = sp(y, x)\n",
        "    ax = np.linspace(0, 1, n)\n",
        "    for i in range(b):\n",
        "        plt.figure()\n",
        "        plt.plot(ax, y[i, :].cpu().numpy(), 'r.', markersize=25)\n",
        "        plt.plot(x[i, :].cpu().numpy(), z[i, :].cpu().numpy(), 'b.')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _demo()"
      ],
      "metadata": {
        "id": "mgisoT5VIlPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b338d0ba-874f-4f76-ae6c-c5173fb5dde0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as utils\n",
        "#import pytorch_ssim\n",
        "import  time \n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.nn.modules.loss import _Loss \n",
        "#from net.Ushape_Trans import *\n",
        "#from dataset import prepare_data, Dataset\n",
        "#from net.utils import *\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
        "#from loss.LAB import *\n",
        "#from loss.LCH import *"
      ],
      "metadata": {
        "id": "eFvSqrR-IhWB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ],
      "metadata": {
        "id": "DS3j1o-LO_Ij"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(img):\n",
        "    output=[]\n",
        "    output.append(F.interpolate(img, scale_factor=0.125))\n",
        "    output.append(F.interpolate(img, scale_factor=0.25))\n",
        "    output.append(F.interpolate(img, scale_factor=0.5))\n",
        "    output.append(img)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Jk6vqjCPPCEK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = 'float32'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "x8m_AABXPF96"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator \n",
        "generator = Generator().cuda()\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/saved_models/G/generator_795.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jXC4k92UhfG",
        "outputId": "650b7a72-c90f-49c5-cb2a-303afab44fac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_x=[]\n",
        "path='/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'#要改\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    #print(\"image path is \"+impath)\n",
        "    imgx= cv2.imread(impath)\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    training_x.append(imgx)   \n",
        "\n",
        "X_train = []\n",
        "\n",
        "for features in training_x:\n",
        "    X_train.append(features)\n",
        "\n",
        "X_train = np.array(X_train)    "
      ],
      "metadata": {
        "id": "CuigyBsaPHI6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.astype(dtype)\n",
        "X_train= torch.from_numpy(X_train)\n",
        "X_train=X_train.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "9_8n3g95PPot"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255.0\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "Zsjg_1M2QVrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7cf35b-3e93-4320-ba2d-4f2634d28d96"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([108, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_y=[]\n",
        "path='/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/GT/'#要改\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    #print(\"开始处理\"+impath)\n",
        "    imgx= cv2.imread(path+item)\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    training_y.append(imgx)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "y_train = []\n",
        "\n",
        "for features in training_y:\n",
        "    y_train.append(features)\n",
        "    \n",
        "\n",
        "    \n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "UEfe2nXYQZjd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.astype(dtype)\n",
        "y_train= torch.from_numpy(y_train)\n",
        "y_train=y_train.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "mY1xsPU5Qbxr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train/255.0\n",
        "y_train.shape"
      ],
      "metadata": {
        "id": "F4fX5jKLQd87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a794638-71ea-45c3-e935-1bf8ac5d5f5c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([108, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x=[]\n",
        "path='/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'#要改\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    #print(\"开始处理\"+impath)\n",
        "    imgx= cv2.imread(path+item)\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    test_x.append(imgx)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "x_test = []\n",
        "\n",
        "for features in test_x:\n",
        "    x_test.append(features)\n",
        "    \n",
        "\n",
        "    \n",
        "x_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "lPmylU2lQgDi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=x_test.astype(dtype)\n",
        "x_test= torch.from_numpy(x_test)\n",
        "x_test=x_test.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "89neL46KQiFy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=x_test/255.0"
      ],
      "metadata": {
        "id": "sfN6bygcQj1L"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "TPdFjIadQl66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5ace2f-c5ea-48b2-e5ce-ea338f73bcad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([108, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as utils\n",
        "#import pytorch_ssim\n",
        "import  time \n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.nn.modules.loss import _Loss \n",
        "#from net.Ushape_Trans import *\n",
        "#from dataset import prepare_data, Dataset\n",
        "#from net.utils import *\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
        "#from loss.LAB import *\n",
        "#from loss.LCH import *\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "xXPQfAXOOy9b"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ],
      "metadata": {
        "id": "GZHhbVNHOX59"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(img):\n",
        "    output=[]\n",
        "    output.append(F.interpolate(img, scale_factor=0.125))\n",
        "    output.append(F.interpolate(img, scale_factor=0.25))\n",
        "    output.append(F.interpolate(img, scale_factor=0.5))\n",
        "    output.append(img)\n",
        "    return output"
      ],
      "metadata": {
        "id": "WsfeV6WoOdrZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = 'float32'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "fL_2ozTGOgwQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator \n",
        "generator = Generator().cuda()\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/saved_models/G/generator_795.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBjtG0o3YIIM",
        "outputId": "615b03fe-7f1c-43de-98fd-2ef9e983b8a7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHHUwKatYTE7",
        "outputId": "577f3ed1-a25a-4697-a796-76d7512e91ac"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (linear_encoding): Linear(in_features=384, out_features=512, bias=True)\n",
              "  (position_encoding): LearnedPositionalEncoding()\n",
              "  (pe_dropout): Dropout(p=0.0, inplace=False)\n",
              "  (transformer): TransformerModel(\n",
              "    (net): IntermediateSequential(\n",
              "      (0): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU()\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU()\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU()\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU()\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_head_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Conv_x): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (rgb_to_feature): ModuleList(\n",
              "    (0): from_rgb(\n",
              "      (conv_1): _equalized_conv2d(32, 3, 1, 1)\n",
              "      (pixNorm): PixelwiseNorm()\n",
              "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (1): from_rgb(\n",
              "      (conv_1): _equalized_conv2d(64, 3, 1, 1)\n",
              "      (pixNorm): PixelwiseNorm()\n",
              "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (2): from_rgb(\n",
              "      (conv_1): _equalized_conv2d(128, 3, 1, 1)\n",
              "      (pixNorm): PixelwiseNorm()\n",
              "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "  )\n",
              "  (feature_to_rgb): ModuleList(\n",
              "    (0): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 32, 1, 1)\n",
              "    )\n",
              "    (1): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 64, 1, 1)\n",
              "    )\n",
              "    (2): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 128, 1, 1)\n",
              "    )\n",
              "    (3): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 256, 1, 1)\n",
              "    )\n",
              "  )\n",
              "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(16, 3, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(16, 16, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(16, 16, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv1_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 16, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv2): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 32, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv2_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 32, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv3): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv3_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv4): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv4_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv5): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 512, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (mtc): ChannelTransformer(\n",
              "    (embeddings_1): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(32, 32, kernel_size=(32, 32), stride=(32, 32))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_2): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(64, 64, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_3): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(128, 128, kernel_size=(8, 8), stride=(8, 8))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_4): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (encoder_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "      (encoder_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "      (encoder_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "      (encoder_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (reconstruct_1): Reconstruct(\n",
              "      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (reconstruct_2): Reconstruct(\n",
              "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (reconstruct_3): Reconstruct(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (reconstruct_4): Reconstruct(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up5): up_conv(\n",
              "    (conv_1): _equalized_conv2d(256, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt5): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv5): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 512, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv5_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up4): up_conv(\n",
              "    (conv_1): _equalized_conv2d(128, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt4): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv4): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv4_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up3): up_conv(\n",
              "    (conv_1): _equalized_conv2d(64, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt3): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv3): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv3_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up2): up_conv(\n",
              "    (conv_1): _equalized_conv2d(32, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt2): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv2): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv2_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 32, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'#要改\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "i=1\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    imgx= cv2.imread(path+item)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx = np.array(imgx).astype(dtype)\n",
        "\n",
        "    imgx= torch.from_numpy(imgx)\n",
        "    imgx=imgx.permute(2,0,1).unsqueeze(0)\n",
        "    imgx=imgx/255.0\n",
        "    #plt.imshow(imgx[0,:,:,:])\n",
        "    #plt.show()\n",
        "    imgx = Variable(imgx).cuda()\n",
        "    #print(imgx.shape)\n",
        "    output=generator(imgx)\n",
        "    out=output[3].data\n",
        "    save_image(out, \"/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/output\"+item, nrow=5, normalize=True)\n",
        "    i=i+1"
      ],
      "metadata": {
        "id": "1Otblm9ZPCBj"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_psnr(img1, img2):\n",
        "   mse = np.mean( (img1/255. - img2/255.) ** 2 )\n",
        "   if mse < 1.0e-10:\n",
        "      return 100\n",
        "   PIXEL_MAX = 1\n",
        "   return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "def compute_mse(img1,img2):\n",
        "    mse=np.mean( (img1/255. - img2/255.) ** 2 )\n",
        "    return mse"
      ],
      "metadata": {
        "id": "SMuKBZU8PQ_2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1='/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/GT/'#要改\n",
        "path2='/content/drive/MyDrive/deepwaterdetection/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/output'#要改\n",
        "path_list = os.listdir(path1)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "PSNR=[]\n",
        "\n",
        "for item in path_list:\n",
        "    impath1=path1+item\n",
        "    impath2=path2+item\n",
        "    imgx= cv2.imread(impath1)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    imgy= cv2.imread(impath2)\n",
        "    imgy=cv2.resize(imgy,(256,256))\n",
        "    #print(imgx.shape)\n",
        "    psnr1=compute_psnr(imgx[:,:,0],imgy[:,:,0])\n",
        "    psnr2=compute_psnr(imgx[:,:,1],imgy[:,:,1])\n",
        "    psnr3=compute_psnr(imgx[:,:,2],imgy[:,:,2])\n",
        "    \n",
        "\n",
        "    psnr=(psnr1+psnr2+psnr3)/3.0\n",
        "\n",
        "    PSNR.append(psnr)"
      ],
      "metadata": {
        "id": "N0T2Ia5OPUNf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR=np.array(PSNR)    \n",
        "print(PSNR.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoDZ2hc_ZGG0",
        "outputId": "94eab5e5-40f1-47a8-a14d-ffeb24ccde66"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.75027621942933\n"
          ]
        }
      ]
    }
  ]
}